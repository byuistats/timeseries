---
title: "Holt-Winters Method (Additive Model)"
subtitle: "Chapter 3: Lesson 3"
format: html
editor: source
sidebar: false
---

```{r}
#| include: false
source("common_functions.R")
```

```{=html}
<script type="text/javascript">
 function showhide(id) {
    var e = document.getElementById(id);
    e.style.display = (e.style.display == 'block') ? 'none' : 'block';
 }
 
 function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
 }    
</script>
```


```{r}
#| echo: false

expand_hw_df <- function(df, date_var, value_var, p = 12, predict_periods = 18) {
  # Note that p must be < nrow(df)
  # Note that predict_periods must be < nrow(df)
  
  # Create new variables
  df$date <- df[[date_var]]
  df$x_t <- df[[value_var]]
  
  df2 <- df |>
    # select(date, x_t) |>  # This deletes all variables in original file
    mutate(
      a_t = as.numeric(NA),
      b_t = as.numeric(NA),
      s_t = as.numeric(NA),
      xhat_t = as.numeric(NA)
    )
  
  header <- df2 |> 
    head(p + 1) |>
    mutate(
      date = date - max(date) + min(date),
      x_t = NA
    ) |>
    head(p)

  footer <- df2 |>
    tail(predict_periods + 1) |>
    mutate(
      date = date - min(date) + max(date),
      x_t = NA
    ) |>
    tail(predict_periods)

  df_final <- header |>
    bind_rows(df2) |>
    bind_rows(footer)
  
  return(df_final)
}

hw_additive_slope_additive_seasonal <- function(df, date_var, value_var, p = 12, predict_periods = 18, alpha = 0.2, beta = 0.2, gamma = 0.2, s_initial = rep(0,p)) {
  
  # Get expanded data frame
  df <- df |> expand_hw_df(date_var, value_var, p, predict_periods)
  
  # Fill in prior belief about s_t
  for (t in 1:p) {
    df$s_t[t] <- s_initial[t]
  }
  
  # Fill in first row of values
  offset <- p # number of header rows to skip
  df$a_t[1 + offset] <- df$x_t[1 + offset]
  df$b_t[1 + offset] <- (1 / p) * mean(df$x_t[(p + 1 + offset):(2 * p + offset)] - df$x_t[(1 + offset):(p + offset)])
  df$s_t[1 + offset] <- (1 - gamma) * df$s_t[1]

  # Fill in remaining rows of body of df with values
  for (t in (2 + offset):(nrow(df) - predict_periods) ) {
    df$a_t[t] = alpha * (df$x_t[t] - df$s_t[t-p]) + (1 - alpha) * (df$a_t[t-1] + df$b_t[t-1])
    df$b_t[t] = beta * (df$a_t[t] - df$a_t[t-1]) + (1 - beta) * df$b_t[t-1]
    df$s_t[t] = gamma * (df$x_t[t] - df$a_t[t]) + (1 - gamma) * df$s_t[t-p]
  }
  
  df <- df |>
    mutate(k = ifelse(row_number() >= nrow(df) - predict_periods, row_number() - (nrow(df) - predict_periods), NA))
  
  # Fill in forecasted values
  offset <- nrow(df) - predict_periods
  for (t in offset:nrow(df)) {
    df$s_t[t] = df$s_t[t - p]
    df$xhat_t[t] = df$a_t[offset] + df$k[t] * df$b_t[offset] + df$s_t[t - p]
  }
  
  # Delete temporary variable k
  df <- df |> select(-k)

  return(df)
}
```


## Learning Outcomes

{{< include outcomes/chapter_3_lesson_3_outcomes.qmd >}}




## Preparation

-   Read Section 3.4.2 (Page 59)



## Learning Journal Exchange (10 mins)

-   Review another student's journal

-   What would you add to your learning journal after reading another student's?

-   What would you recommend the other student add to their learning journal?

-   Sign the Learning Journal review sheet for your peer



## Class Discussion: Theory Supporting the EWMA



## Introduction to the Holt-Winters Method (Additive Model)

We will describe the historical progression that led to the Holt-Winters method.

### Review: Exponentially Weighted Moving Average (EWMA) or Simple Exponential Smoothing

The exponential weighted moving average (EWMA) is a simple method for smoothing (or filtering) a time series. The  update equation for the estimate of the level of the time series is

$$
  a_t = \alpha x_t + (1-\alpha) a_{t-1}
$$

where $a_t$ is the estimate of the level of the time series at time $t$ and $0 \le \alpha \le 1$ is the smoothing paramter.

This is known as the **level update equation**, because at each time step, we can update our estimate of the level (or the center) of the time series.
It is called exponential smoothing, because at each preceding value has exponentially decreasing influence on the estimate.

<!-- Check Your Understanding -->

::: {.callout-tip icon=false title="Check Your Understanding"}

-   Explain the level update equation to your partner.

:::

These computations are based on previous values and $a_1 = x_1$. The number $0 \le \alpha \le 1$ is a smoothing parameter. This determines how much weight is given to previous values when creating the updated level estimate.

If you were to use this model for forecasting, you would not be able to consider any trend or seasonality in the forecast. Hence, the future values would all be forecasted as the last value of $a_n$:

$$
  \hat x_{n+k|n} = a_n
$$
where $\hat x_{n+k \mid n}$ is the estimate of the time series $k$ time units in the future past time $t=n$.
Frankly, this is not very useful, because many time series have trends or seasonality.

### Holt's Exponential Smoothing

In 1957, Charles Holt published a new procedure that introduced a trend into this model. The forecasted values were:

$$
  \hat x_{n+k|n} = a_n + k b_n
$$

where $b_n$ is the slope indicating how much the time series changes on average from one time point to another and $k$ is the number of time periods past $t=n$ you are forecasting.

This method uses the same level update equation as EMWA.
The slope update equation is:

$$
  b_t = \beta \left( a_t - a_{t-1} \right) + (1-\beta) b_{t-1}
$$

where $0 \le \beta \le 1$ is a smoothing parameter, $b_t$ is the slope estimate at time $t$, and $a_t$ is the estimate of the level of the time series at time $t$.


### Holt-Winters Filtering (Winters' Exponential Smoothing)

Peter Winters, a colleague of Holt's at the Carnagie Institute of Technology, published an enhancement of Winters' technique in 1960 that allowed for seasonal variation. This is known as the **Holt-Winters Method** or **Holt-Winters Filtering**.

#### Forecast Equation

The forecast equation is:

$$
  \hat x_{n+k|n} = a_n + k b_n + s_{n+k-p}
$$

where $\hat x_{n+k|n}$ is the forecasted value of the time series $k$ units in the future after time $t=n$, and the time series is assumed to have seasonality with a period of $p$ time units; $a_n$ is the level of the time series at time $t=n$; $b_n$ is the slope of the time series at time $t=n$; and $s_{n+k-p}$ is the estimated seasonal component at time $t=n+k-p$. Note that we must look back one full period to get the estimated seasonal component.

#### Update Equations

There are three update equations, one each for $a_t$ (level), $b_t$ (slope), and $s_t$ (seasonal component).

\begin{align*}
  a_t &= \alpha \left( x_t - s_{t-p} \right) + (1-\alpha) \left( a_{t-1} + b_{t-1} \right) && \text{Level} \\
  b_t &= \beta \left( a_t - a_{t-1} \right) + (1-\beta) b_{t-1} && \text{Slope} \\
  s_t &= \gamma \left( x_t - a_t \right) + (1-\gamma) s_{t-p} && \text{Seasonal}
\end{align*}

where $\{x_t\}$ is a time series from $t=1$ to $t=n$ that has seasonality with a period of $p$ time units; at time $t$, $a_t$ is the estimated level of the time series, $b_t$ is the estimated slope, and $s_t$ is the estimated seasonal component; and $\alpha$, $\beta$, and $\gamma$ are parameters (all between 0 and 1).


<!-- Check Your Understanding -->

::: {.callout-tip icon=false title="Check Your Understanding"}

Consider the following update equations and answer the questions associated with each.

$$
a_t = \alpha \cdot \underbrace{ \left( x_t - s_{t-p} \right) }_{A} + (1-\alpha) \cdot  \underbrace{ \left( a_{t-1} + b_{t-1} \right) }_{B}
~~~~~~~~~~~~~~~~~~~~ \text{Level}
$$


-   Interpret the term $A = x_t - s_{t-p}$.
-   Interpret the term $B = a_{t-1} - b_{t-1}$.
-   Explain why this expression for $a_t$ estimates the level of the time series at time $t$.

$$
b_t = \beta \cdot \underbrace{ \left( a_t - a_{t-1} \right) }_{C} + (1-\beta) \cdot \underbrace{ b_{t-1} }_{D}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \text{Slope}
$$

-   Interpret the term $C = a_t - a_{t-1}$.
-   Interpret the term $D = b_{t-1}$.
-   Explain why this expression for $b_t$ estimates the slope of the time series at time $t$.

$$
s_t = \gamma \cdot \underbrace{ \left( x_t - a_t \right) }_{E} + (1-\gamma) \cdot \underbrace{ s_{t-p} }_{F}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \text{Seasonal}
$$

-   Interpret the term $E = x_t - a_t$.
-   Interpret the term $F = s_{t-p}$.
-   Explain why this expression for $s_t$ estimates the seasonal component of the time series at time $t$.
-   When the seasonal component appears on the right-hand side of the update equations, it always given as $s_{t-p}$. Why do we use the estimate of the seasonal effect $p$ periods ago? Why not apply a more recent value?
-   What do the following sets of terms have in common?
    -   $\{A, C, E \}$
    -   $\{B, D, F \}$
-   Explain why the Holt-Winters method works.

:::

#### Initial Estimates of $a_t$, $b_t$, and $s_t$

We can use the update equations to compute the next value of $a_t$, $b_t$, and $s_t$, once we get going. Yet, how do we get started? What are the initial values of these estimates?

##### Estimating $a_1$:

It is reasonable to let $a_1 = x_t$. We simply start our estimate of the level of the time series at the initial data value.

##### Estimating $b_1$:

For the value of $b_1$, the Cowpertwait textbook vaguely suggests estimating this from the data or setting it to zero. Setting $b_1$ to zero is problematic, because it adversely affects the level and slope estimates at the beginning of the time series. We need a better way.

<!-- Check Your Understanding -->

::: {.callout-tip icon=false title="Check Your Understanding"}

-   Interpret the quantity
$$
  \dfrac{x_{p+1} - x_{1}}{p}
$$

:::

We will approximate $b_1$ by averaging the slope between pairs of points one period apart. Recall that $p$ is the number of observations per period. (Monthly data which have an annual cycle would have $p=12$. Daily data with a weekly cycle have $p=7$.) Note that the fraction in the "Check Your Understanding" box above is an estimate of the slope of the time series as it moves from time $1$ to time $p+1$. These are the first observations in the first two cycles. We compute these estimated slopes for all the paired observations in the first two cycles, then we compute the mean of these slopes. This is reflected in the expression for $b_1$:

$$
  b_1 =
    \frac{
      \left(
        \dfrac{x_{p+1} - x_{1}}{p} +
        \dfrac{x_{p+2} - x_{2}}{p} +
        \dfrac{x_{p+3} - x_{3}}{p} +
        \cdots +
        \dfrac{x_{2p-1} - x_{p-1}}{p} +
        \dfrac{x_{2p} - x_{p}}{p}
      \right)
    }{p}
$$

##### Estimating $s_1, s_2, \ldots s_p$:

The initial $p$ values of the seasonal effects, $s_1, s_2, \ldots s_p$, can be determined either by estimating based on the data or your prior experience; alternatively, they could be set to 0.
For $t=1, 2, 3, \ldots, p$ iterations, use your estimate for $s_t$ when the formulas call for $s_{t-p}$.


<!-- Check Your Understanding -->

::: {.callout-tip icon=false title="Check Your Understanding"}

-   Explain why it is reasonable to let $a_1 = x_1$.
-   What does the term
    $$
      \dfrac{x_{p+1} - x_{1}}{p}
    $$
    estimate?
-   Why does the average of the values
    $$
      \left\{
          \dfrac{x_{p+1} - x_{1}}{p}, ~
          \dfrac{x_{p+2} - x_{2}}{p}, ~
          \dfrac{x_{p+3} - x_{3}}{p}, ~
          \cdots, ~
          \dfrac{x_{2p-1} - x_{p-1}}{p}, ~
          \dfrac{x_{2p} - x_{p}}{p}
      \right\}
    $$
    give a good estimate of the slope at the beginning of the time series?
-   Suppose you needed to estimate $s_1, s_2, s_3, \ldots, s_p$ for monthly sales data, where sales are highest in the summer months and lowest in the winter months. If January corresponds to month 1, which values of $s_t$ would you set to be positive? negative? near zero?

:::

::: {.callout-note}
To implement the initial seasonality estimates, we include them in the model as 
$$
  s_{1-p}, s_{2-p}, s_{3-p}, \ldots, s_{p-p}
$$
so we can begin to update these values in the first cycle of seasonality ($t = 1, 2, 3, \ldots, p$).
:::

### Illustration of the Holt-Winters Method for a Sample Time Series

The Holt-Winters method provides a way to model a time series in which we consider the time series in layers. first, there is the level (the smoothed $x_t$ values from the time series) at time $t$. We will denote the *level* by $a_t$. The level can change from time to time.
We introduce a value $b_n$, which we call the *slope*. This is the change in the level of the series from one time period to another. (As the book points out, R and many textbooks call the slope the *trend*.)
Finally, we include a seasonal estimate, $s_t$, which indicates how much the time series rises or falls above the level and trend values at time $t$.

To visualize these terms, it can be helpful to consider the forecasting model. Suppose we have computed that Holt-Winters estimate of a time series with $n$ observations. In other words, we have just fit a curve to the entire time series.
We will use a very simple time series for this illustration.

First, consider a time series that has a seasonal pattern of (100, 104, 100, 100) with zero trend and random components. This is illustrated in @fig-flat-example-ts.

```{r}
#| label: fig-flat-example-ts
#| fig-cap: "Sample time series with zero trend and random components"
#| warning: false
#| echo: false

a <- function(t) { 100 }
b <- function(t) { 0 }
s <- function(t) { (t %% 4 == 2) * 3 }
x <- function(t) { a(t) + (t-1) * b(t) + s(t) }
n_months <- 36
max_k <- 16

start_date <- my(paste(1, floor(year(now())-n_months/12)))
date_seq <- seq(start_date,
    start_date + months(n_months - 1),
    by = "1 months")

temp_ts <- data.frame(date = yearmonth(date_seq), value = x(1:n_months)) |>
  as_tsibble(index = date)
temp_ts |>
  autoplot(.vars = value) +
  coord_cartesian(ylim = c(95,130)) +
    labs(
      x = "Date",
      y = "Value",
      title = "Sample Time Series with Zero Slope",
      color = "Components"
    ) +
    theme_minimal() +
    theme(legend.position = "none") +
    theme(
      plot.title = element_text(hjust = 0.5)
    )
```

Now, we add a slope of $\frac{1}{2}$ to this time series. In @fig-sloped-example-ts, we observe the same sample time series, but with the added component of a slope.

```{r}
#| label: fig-sloped-example-ts
#| fig-cap: "Sample time series with a trend"
#| warning: false
#| echo: false

a <- function(t) { 100 }
b <- function(t) { 1/2 }
s <- function(t) { (t %% 4 == 2) * 3 }
x <- function(t) { a(t) + (t-1) * b(t) + s(t) }
n_months <- 36
max_k <- 16

start_date <- my(paste(1, floor(year(now())-n_months/12)))
date_seq <- seq(start_date,
    start_date + months(n_months - 1),
    by = "1 months")

temp_ts <- data.frame(date = yearmonth(date_seq), value = x(1:n_months)) |>
  as_tsibble(index = date)
temp_ts |>
  autoplot(.vars = value) +
    coord_cartesian(ylim = c(95,130)) +
    labs(
      x = "Date",
      y = "Value",
      title = "Sample Time Series with Positive Slope",
      color = "Components"
    ) +
    theme_minimal() +
    theme(legend.position = "none") +
    theme(
      plot.title = element_text(hjust = 0.5)
    )
```

Next, we apply the Holt-Winters method to these data. @fig-hw-example-ts illustrates the Holt-Winters filter plotted against the data.

```{r}
#| label: fig-hw-example-ts
#| fig-cap: "Sample time series illustrating the Holt-Winters filter"
#| echo: false
#| warning: false

temp_ts |> 
  hw_additive_slope_additive_seasonal("date", "value", p = 4, predict_periods = 16) |>
  ggplot(aes(x = date)) +
    geom_line(aes(y = x_t), color = "black", size = 1) +
    geom_line(aes(y = a_t + s_t, color = "Combined", alpha=0.5), size = 1) +
    geom_line(aes(y = xhat_t, color = "Combined", alpha=0.5), linetype = "dashed", size = 1) +
    coord_cartesian(ylim = c(95,130)) +
    labs(
      x = "Date",
      y = "Value",
      title = "Sample Time Series with Holt-Winters Forecast",
      color = "Components"
    ) +
    theme_minimal() +
    theme(legend.position = "none") +
    theme(
      plot.title = element_text(hjust = 0.5)
    )
```

::: {.callout-tip icon=false title="Check Your Understanding"}


-   What do you observe?

:::



## Small Group Activity: Holt-Winters Model for Residential Natural Gas Consumption (25 min)

```{r}
#| echo: false
#| warning: false

# nat_gas <- rio::import("https://byuistats.github.io/timeseries/data/natural_gas_res.csv") |>
nat_gas_raw <- rio::import("data/natural_gas_res.csv") |>
  mutate(date = my(month)) |>
  filter(date >= my("Jan 2017"))
nat_gas <- nat_gas_raw |>
  mutate(quarter = yearquarter(date)) |>
  group_by(quarter) |> 
  summarize(
    gas_use_mmcf = sum(residential_nat_gas_consumption),
    n = n()
  ) |>
  filter(n == 3) |>  # Eliminate partial quarter(s)
  dplyr::select(-n) |>
  mutate(gas_billion_cf = round(gas_use_mmcf / 10^3))
```

The United States Energy Information Administration (EIA) [publishes data](https://www.eia.gov/dnav/ng/ng_cons_sum_dcu_nus_m.htm) on the total residential natural gas consumption in the country. The government publishes monthly data beginning in January 1973. For the purpose of this example, we will only consider quarterly values beginning in 2017. The data are given in MMcf (thousand-thousand cubic feet, or millions of cubic feet). We convert the data to billions of cubic feet (Bcf) and round to the nearest integer to make the numbers a little more manageable.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#| eval: false

nat_gas <- rio::import("https://byuistats.github.io/timeseries/data/natural_gas_res.csv") |>
  mutate(date = my(month)) |>
  filter(date >= my("Jan 2017")) |>
  mutate(quarter = yearquarter(date)) |>
  group_by(quarter) |> 
  summarize(
    gas_use_mmcf = sum(residential_nat_gas_consumption),
    n = n()
  ) |>
  filter(n == 3) |>  # Eliminate partial quarter(s)
  dplyr::select(-n) |>
  mutate(gas_billion_cf = round(gas_use_mmcf / 10^3))
```

```{r}
#| echo: false
nat_gas |>
  display_partial_table(6,6)
```

The quarters consist of the following months:
-   **Quarter 1:** Jan, Feb, Mar
-   **Quarter 2:** Apr, May, Jun
-   **Quarter 3:** Jul, Aug, Sep
-   **Quarter 4:** Oct, Nov, Dec

The weather is colder in the first and fourth quarters, so the demand for natural gas will be higher then. Also, the demand for natural gas over the four quarters can easily vary by as much as 2000 Bcf. We will use this information to create an initial estimate of the seasonality of the time series. We will assume that in Quarters 1 and 4, natural gas use is 1000 Bcf above the level of the time series and in Quarters 2 and 3, it is 1000 Bcf below the level of the time series. 

The part of the time series we are using begins in Quarter 1 of 2017. So we will let
$$
  s_{Q1} = 1000, ~~~ s_{Q2} = -1000, ~~~ s_{Q3} = -1000, ~~~ s_{Q4} = 1000
$$

There are $p=4$ quarters in a year. 
We implement initial seasonality estimates in the Holt-Winters model as 
$$
  s_{1-p} = s_{(-3)} = 1000, ~~~ s_{2-p} = s_{(-2)} = -1000, ~~~ s_{3-p} = s_{(-1)} = -1000, ~~~ s_{4-p} = s_{0} = 1000
$$

```{r}
#| echo: false
#| warning: false

hw_additive_slope_additive_seasonal_gas <- function(df, date_var, value_var, p = 12, predict_periods = 18, alpha = 0.2, beta = 0.2, gamma = 0.2, s_initial = rep(0,p)) {
  
  # Get expanded data frame
  df <- df |> expand_hw_df(date_var, value_var, p, predict_periods)
  
  # Fill in prior belief about s_t
  for (t in 1:p) {
    df$s_t[t] <- s_initial[t]
  }
  
  # Fill in first row of values
  offset <- p # number of header rows to skip
  df$a_t[1 + offset] <- round( df$x_t[1 + offset] )
  df$b_t[1 + offset] <- round( (1 / p) * mean(df$x_t[(p + 1 + offset):(2 * p + offset)] - df$x_t[(1 + offset):(p + offset)]) )
  df$s_t[1 + offset] <- round( (1 - gamma) * df$s_t[1] )

  # Fill in remaining rows of body of df with values
  for (t in (2 + offset):(nrow(df) - predict_periods) ) {
    df$a_t[t] = round( alpha * (df$x_t[t] - df$s_t[t-p]) + (1 - alpha) * (df$a_t[t-1] + df$b_t[t-1]) )
    df$b_t[t] = round( beta * (df$a_t[t] - df$a_t[t-1]) + (1 - beta) * df$b_t[t-1] )
    df$s_t[t] = round( gamma * (df$x_t[t] - df$a_t[t]) + (1 - gamma) * df$s_t[t-p] )
  }
  
  df <- df |>
    mutate(k = ifelse(row_number() >= nrow(df) - predict_periods, row_number() - (nrow(df) - predict_periods), NA))
  
  # Fill in forecasted values
  offset <- nrow(df) - predict_periods
  for (t in offset:nrow(df)) {
    df$s_t[t] = round( df$s_t[t - p] )
    df$xhat_t[t] = round( df$a_t[offset] + df$k[t] * df$b_t[offset] + df$s_t[t - p] )
  }
  
  # Delete temporary variable k
  df <- df |> select(-k)
  
  return(df)
}

nat_gas_ts <- nat_gas |>
  hw_additive_slope_additive_seasonal_gas("quarter", "gas_billion_cf", p = 4, predict_periods = 9, s_initial = c(1000, -1000, -1000, 1000)) |>
  as_tsibble(index = date) %>%  
  mutate(t = (1 - 4):(nrow(.) - 4)) |>
  dplyr::select(date, t, x_t, a_t, b_t, s_t, xhat_t)

nat_gas_ts |>
  mutate(
    xhat_t = 
      case_when(
        t %in% c(1:6, 26:nrow(nat_gas_ts)) ~ NA,
        t %in% c(7:25) ~ a_t + s_t,
        TRUE ~ xhat_t
      ),
    a_t = ifelse(t %in% c(1:6, 26:27), NA, a_t),
    b_t = ifelse(t %in% c(1:6, 26:27), NA, b_t),
    s_t = ifelse(t %in% c(1:6, 26:nrow(nat_gas_ts)), NA, s_t)
  ) |>
  rename(
    "$$Quarter$$" = date,
    "$$t$$" = t,
    "$$x_t$$" = x_t,
    "$$a_t$$" = a_t,
    "$$b_t$$" = b_t,
    "$$s_t$$" = s_t,
    "$$\\hat x_t$$" = xhat_t,
  ) |>
  replace_na_with_char() |>
  display_table("0.75in")
```


```{r}
#| echo: false
#| warning: false

nat_gas_ts |>
  ggplot(aes(x = date)) +
    geom_line(aes(y = x_t), color = "black", size = 1) +
    geom_line(aes(y = a_t + s_t, color = "Combined", alpha=0.5), size = 1) +
    geom_line(aes(y = xhat_t, color = "Combined", alpha=0.5), linetype = "dashed", size = 1) +
    coord_cartesian(ylim = c(0,2500)) +
    labs(
      x = "Date",
      y = "Natural Gas Use (Billions of Cubic Feet)",
      title = "U.S. Residential Natural Gas Consumption, by Quarter",
      color = "Components"
    ) +
    theme_minimal() +
    theme(legend.position = "none") +
    theme(
      plot.title = element_text(hjust = 0.5)
    )
```



## Small Group Activity: Holt-Winters Model for BYU-Idaho Enrollment Data (25 min) --- MULTIPLICATIVE

In Chapter 2, Lesson 3, we explored the BYU-Idaho Enrollment data. We will apply the Holt-Winters model to these data with $\alpha = \beta = \gamma = 0.2$. @fig-enrollment-ts illustrates these data.

```{r}
#| label: fig-enrollment-ts
#| fig-cap: "Time Series Plot of BYU-Idaho Campus Enrollments"
#| code-fold: true
#| code-summary: "Show the code"
#| warning: false
# read in the data from a csv and make the tsibble

# byui_enrollment_ts <- rio::import("https://byuistats.github.io/timeseries/data/byui_enrollment_2012.csv") |>
byui_enrollment_ts <- rio::import("data/byui_enrollment_2012.csv") |> 
  rename(
    semester = "TermCode",
    year = "Year",
    enrollment = "On Campus Enrollment (Campus HC)"
  ) |>
  mutate(
    term = 
      case_when(
        left(semester, 2) == "WI" ~ 1,
        left(semester, 2) == "SP" ~ 2,
        left(semester, 2) == "FA" ~ 3,
        TRUE ~ NA
      )
  ) |>
  filter(!is.na(term)) |>
  mutate(dates = yearmonth( ym( paste(year, term * 4 - 3) ) ) ) |>
  dplyr::select(semester, dates, enrollment) |>
  as_tsibble(index = dates)
# |>
# filter(dates >= my("May 2019"))

byui_enrollment_ts |> 
  as_tibble() |>
  hw_additive_slope_additive_seasonal("dates", "enrollment", p = 3, predict_periods = 12) |>
  as_tsibble(index = date) |>
  ggplot(aes(x = date)) +
    geom_line(aes(y = x_t), color = "black", size = 1) +
    geom_line(aes(y = a_t + s_t, color = "Combined", alpha=0.5), size = 1) +
    geom_line(aes(y = xhat_t, color = "Combined", alpha=0.5), linetype = "dashed", size = 1) +
    # coord_cartesian(ylim = c(95,130)) +
    labs(
      x = "Date",
      y = "Value",
      title = "BYU-Idaho Enrollments with Holt-Winters Forecast",
      color = "Components"
    ) +
    theme_minimal() +
    theme(legend.position = "none") +
    theme(
      plot.title = element_text(hjust = 0.5)
    )
```


```{r}
enrollment_ts <- rio::import("https://byuistats.github.io/timeseries/data/byui_enrollment.csv") |>
  mutate(dates = yearmonth( ym( paste(year, term * 4 - 3) ) ) ) |>
  dplyr::select(semester, dates, enrollment) |>
  as_tsibble(index = dates)

extra_terms <- enrollment_ts |>
  tail(6) |>
  mutate(dates = yearmonth(ym(dates) + years(2))) |>
  mutate(
    semester = paste0(
      left(semester, 2),
      as.integer(right(semester, 2)) + 2
      )
  ) |>
  mutate(enrollment = NA)

enrollment_ts |>
  bind_rows(extra_terms) |>
  autoplot(.vars = enrollment) +
    labs(
      x = "Time",
      y = "Enrollment",
      title = paste0("BYU-Idaho On-Campus Enrollment Counts")
    ) +
    theme(
      plot.title = element_text(hjust = 0.5)
    )
```


@tbl-enrollment-table summarizes the intermediate values for Holt-Winters filtering.

```{r}
#| label: tbl-enrollment-table
#| tbl-cap: "Holt-Winters Smoothing for BYU-Idaho campus enrollments"
#| warning: false
#| echo: false

# Set parameters
p <- 3
alpha <- 0.2
beta <- 0.2
gamma <- 0.2

enroll <- enrollment_ts |>
  as_tibble() |>
  rename(x_t = enrollment) |>
  mutate(
    t = row_number(),
    a_t = 0,
    b_t = 0,
    s_t = 0,
  ) |>
  dplyr::select(semester, t, x_t, a_t, b_t, s_t)

# initialize a1
enroll$a_t[1] = enroll$x_t[1]

# initialize b1
enroll$b_t[1] <-
  (1 / p) * mean( enroll$x_t[(p+1):(2*p)] - enroll$x_t[1:p] )

# First cycle
for (t in 2:p) {
  enroll$a_t[t] <-
    alpha * (enroll$x_t[t] - enroll$s_t[t - 0 * p ]) +
    (1 - alpha) * (enroll$a_t[t - 1] + enroll$b_t[t - 1])
  enroll$b_t[t] <-
    beta * (enroll$a_t[t] - enroll$a_t[t - 1]) +
    (1 - beta) * enroll$b_t[t - 1]
}
enroll$s_t[1] <- enroll$s_t[2] <- enroll$s_t[3] <- 0

for (t in (p + 1):nrow(enroll)) {
  enroll$a_t[t] <-
    alpha * (enroll$x_t[t] - enroll$s_t[t - p]) +
    (1 - alpha) * (enroll$a_t[t - 1] + enroll$b_t[t - 1])
  enroll$b_t[t] <-
    beta * (enroll$a_t[t] - enroll$a_t[t - 1]) +
    (1 - beta) * enroll$b_t[t - 1]
  enroll$s_t[t] <-
    gamma * (enroll$x_t[t] - enroll$a_t[t]) +
    (1 - gamma) * enroll$s_t[t - p]
}

final_season <- c(
  enroll$s_t |> tail(3),
  enroll$s_t |> tail(3)
)

enroll_extension <- enroll |>
  tail(6) |>
  mutate(
    semester = paste0(
      left(semester, 2),
      as.integer(right(semester, 2)) + 2
      ),
    t = t + 6,
    x_t = NA,
    a_t = NA,
    b_t = NA,
    s_t = NA,
    est =
      enroll$a_t[nrow(enroll)] +
      row_number() * enroll$b_t[nrow(enroll)] +
      final_season[row_number()]
  )

enroll |>
  bind_rows(enroll_extension) |>
  mutate(
    est = case_when(
      row_number() == 1 ~ x_t,
      row_number() <= nrow(enroll) ~ a_t + s_t,
      TRUE ~ est
    )
  ) |>
  rename(
    "$$Semester$$" = semester,
    "$$t$$" = t,
    "$$x_t$$" = x_t,
    "$$a_t$$" = a_t,
    "$$b_t$$" = b_t,
    "$$s_t$$" = s_t,
    "$$\\hat x_t$$" = est
  ) |>
  round_df(0) |>
  blank_out_cells_in_df(ncols_to_keep = 6, nrows_to_keep = 0) |>
  blank_out_partial_row(row_number = 1, first_column_number = 4) |>
  blank_out_partial_row(row_number = 2, first_column_number = 4) |>
  blank_out_partial_row(row_number = 3, first_column_number = 4) |>
  blank_out_partial_row(row_number = 4, first_column_number = 4) |>
  blank_out_partial_row(row_number = 5, first_column_number = 4) |>
  blank_out_partial_row(row_number = 6, first_column_number = 4) |>
  blank_out_partial_row(row_number = 13, first_column_number = 4) |>
  blank_out_partial_row(row_number = 14, first_column_number = 4) |>
  mutate(
    across(everything(), ~replace_na(.x, ""))
  ) |>
  display_table("0.75in")
```

<!-- Check Your Understanding -->

::: {.callout-tip icon=false title="Check Your Understanding"}

You will apply Holt-Winters filtering to these data.
-   Find $a_1$
-   Find $b_1$
-   Letting $s_1 = s_2 = s_3 = 0$, compute the values of $a_t$, $b_t$, and $s_t$ for all semesters for which the enrollment counts have been reported.
-   Find $\hat x_t$ for all rows. Note that the expression to compute $\hat x_t$ is different for the rows with data versus the rows where forecasting is required.
-   Superimpose a sketch of your Holt-Winters filter and the associated forecast on @fig-enrollment-ts.

:::





```{r}
#| include: false
#| eval: false

# THIS IS A SUCCESSFUL TEST OF THIS FUNCTION.
# THE FUNCTION IS IN THE common_functions FILE

holt_winters_additive_forecast(enrollment_ts, "enrollment", alpha = 0.2, beta = 0.2, gamma = 0.2, p = 3, a1 = NULL, b1 = NULL, s1 = NULL) |>
  display_table()
```



<!-- ### Working above here -->

<!-- We will practice forecasting, before we discuss how to get the values of $a_t$, $b_t$, and $s_t$. -->

<!-- The Holt-Winters method was applied to the chocolate search data. @tbl-hw-choc-search summarizes the results for the last few values of the time series. The variable $\hat x_t$ represents the Holt-Winters estimate. (*Note that we have not yet learned how to get these values.*) -->

<!-- ```{r} -->
<!-- #| label: tbl-hw-choc-search -->
<!-- #| tbl-cap: "Holt-Winters estimate for the chocolate search data" -->
<!-- #| echo: false -->

<!-- # read in the data from a csv and make the tsibble -->
<!-- # change the line below to include your file path -->
<!-- chocolate_month_ts <- rio::import("https://byuistats.github.io/timeseries/data/chocolate.csv") |> -->
<!--   mutate( -->
<!--     dates = yearmonth(ym(Month)), -->
<!--     month = month(dates), -->
<!--     year = year(dates), -->
<!--     value = chocolate -->
<!--   ) |> -->
<!--   dplyr::select(dates, month, year, value) |> -->
<!--   as_tsibble(index = dates) -->

<!-- choc_hw_additive <- holt_winters_additive_forecast(chocolate_month_ts, "value", alpha = 0.2, beta = 0.2, gamma = 0.2, p = 12, a1 = NULL, b1 = NULL, s1 = NULL) |> -->
<!--   dplyr::select(-month, -year) -->

<!-- p <- 12 -->
<!-- num_row_of_choc_data_to_keep <- 18 -->
<!-- max_k <- p + 2 -->

<!-- start_date <- ym(max(choc_hw_additive$dates)) + months(1) -->
<!-- date_seq <- seq(start_date, -->
<!--     start_date + months(max_k - 1), -->
<!--     by = "1 months") -->

<!-- tail1 <- choc_hw_additive %>% mutate(n = row_number()) %>% tail(1) -->
<!-- an <- tail1$estimated_level[1] -->
<!-- bn <- tail1$estimated_slope[1] -->
<!-- n <- tail1$n[1] -->

<!-- choc_hw_ts <- choc_hw_additive %>% -->
<!--   bind_rows(data.frame(dates = yearmonth(ymd(date_seq)), value = NA, estimated_level = NA, estimated_slope = NA, estimated_seasonal = NA)) -->

<!-- choc_hw_ts2 <- choc_hw_ts |> -->
<!--   mutate(hw_estimate = estimated_level + estimated_seasonal) -->

<!-- for (k in (n+1):(n+max_k)) { -->
<!--   choc_hw_ts2$estimated_seasonal[k] <- choc_hw_ts2$estimated_seasonal[k - 12] ######### MAGIC NUMBER: 12 periods per cycle -->
<!--   choc_hw_ts2$hw_estimate[k] <- an + (k - n) * bn + choc_hw_ts2$estimated_seasonal[k] -->
<!-- } -->

<!-- choc_hw_ts3 <- choc_hw_ts2 |> -->
<!--   tail(num_row_of_choc_data_to_keep + max_k) |> -->
<!--   convert_df_to_char(3) -->

<!-- for (row_num in (num_row_of_choc_data_to_keep + 1):nrow(choc_hw_ts3)) { -->
<!--   for(col_num in 2:5) { -->
<!--     choc_hw_ts3[row_num, col_num] <- "â€”" -->
<!--   } -->
<!-- } -->

<!-- choc_hw_ts3 |> -->
<!--   blank_out_cells_in_df(ncols_to_keep = 5, nrows_to_keep = num_row_of_choc_data_to_keep - 1) |> -->
<!--   rename( -->
<!--     "$$Dates$$" = dates, "$$x_t$$" = value, "$$a_t$$" = estimated_level, "$$b_t$$" = estimated_slope, "$$s_t$$" = estimated_seasonal, "$$\\hat x_t$$" = hw_estimate -->
<!--   ) |> -->
<!--   display_partial_table(0,num_row_of_choc_data_to_keep + max_k,"0.75in") -->
<!-- ``` -->

























## Small Group Activity: Application of Holt-Winters in R using the Baltimore Crime Data (20 min)

### Background 

The City of Baltimore publishes crime data, which can be accessed through a query. 
This dataset is sourced from the City of Baltimore Open Data. 
You can explore the data on [data.world](https://data.world/data-society/city-of-baltimore-crime-data).

Use the following code to import the data:


<!-- **Packages** -->
<!-- ```{r, warning=FALSE} -->
<!-- # library(dplyr) -->
<!-- # library(tidyr) -->
<!-- # library(ggplot2) -->
<!-- # library(tidyverse) -->
<!-- # library(dygraphs) -->
<!-- # library(tidyquant) -->
<!-- # library(forecast) -->
<!-- ``` -->



```{r}
#| code-fold: true
#| code-summary: "Show the code"

crime_df <- rio::import("https://byuistats.github.io/timeseries/data/baltimore_crime.parquet")

```



The data set consists of `r nrow(crime_df)` rows and `r ncol(crime_df)` columns. 
There are a few key variables:

- **Date and Time:** Records the date and time of each incident.
- **Location:** Detailed coordinates of each incident.
- **Crime Type:** Description of the type of crime.

When exploring a new time series, it is crucial to carefully examine the data. Here are a few rows of the original data set. Note that the data are not sorted in time order.

```{r}
#| echo: false

# View data
crime_df |> 
  display_partial_table(6,3)
```


<!-- Check Your Understanding -->

::: {.callout-tip icon=false title="Check Your Understanding"}

-   Using the command `crime_df |> summary()`, we learn that the `Total.Incidents` always equals 1. What does each row in the data frame represent?

:::

We now summarize the data into a daily tsibble.

```{r}
#| code-fold: true
#| code-summary: "Show the code"

# Data Summary and Aggregation
# Group by dates column and summarize from Total.Incidents column
daily_summary_df <- crime_df |>
  rename(dates = CrimeDate) |>
  group_by(dates) |>
  summarise(incidents = sum(Total.Incidents))

# Data Transformation and Formatting
# Select relevant columns, format dates, and arrange the data
crime_data <- daily_summary_df |>
  mutate(dates = mdy(dates)) |>
  mutate(
    month = month(dates),
    day = day(dates),
    year = year(dates)
  ) |>
  arrange(dates) |>
  dplyr::select(dates, month, day, year, incidents)
  
# Convert formatted data to a tsibble with dates as the index
crime_tsibble <- as_tsibble(crime_data, index = dates) 
```

Here are a few rows of the data when summarized daily.

```{r}
#| echo: false

# View data
crime_tsibble |>
  display_partial_table(6,3) 
```

Here is a time plot of the number of crimes reported in Baltimore daily.

```{r}
#| code-fold: true
#| code-summary: "Show the code"

# Time series plot of total incidents over time
crime_plot <- autoplot(crime_tsibble, .vars = incidents) +
  labs(
    x = "Time",
    y = "Total Crime Incidents",
    title = "Total Crime Incidents Over Time"
  ) +
  theme(plot.title = element_text(hjust = 0.5))

# Display the plot
crime_plot
```

<!-- Check Your Understanding -->

::: {.callout-tip icon=false title="Check Your Understanding"}

-   What do you notice about this time plot?
    - Describe the trend
    - Is there evidence of seasonality?
    - Is the additive or multiplicative model appropriate?
    - Which date has the highest number of recorded crimes? Can you determine a reason for this spike?

:::


The following table summarizes the number of days in each month for which crime data were reported.

```{r}
#| code-fold: true
#| code-summary: "Show the code"

crime_data |>
  mutate(month_char = format(as.Date(dates), '%b') ) |>
  group_by(month, month_char, year) |>
  summarise(n = n(), .groups = "keep") |>
  group_by() |>
  arrange(year, month) |>
  dplyr::select(-month) |>
  rename(Year = year) |>
  pivot_wider(names_from = month_char, values_from = n) |>
  display_table()
```


<!-- Check Your Understanding -->

::: {.callout-tip icon=false title="Check Your Understanding"}

-   What do you observe about the data?
-   What are some problems that could arise from incomplete data?
-   How do you recommend we address the missing data?

:::


### Monthly Summary

We could analyze the data at the daily level, but for simplicity we will model the monthly totals.

```{r}
#| code-fold: true
#| code-summary: "Show the code"

crime_monthly_ts <- crime_tsibble |>
  as_tibble() |>
  mutate(months = yearmonth(dates)) |>
  group_by(months) |>
  summarize(value = sum(incidents)) |>
  as_tsibble(index = months) 

# Plot mean annual total incidents using autoplot
autoplot(crime_monthly_ts, .vars = value) +
  labs(
    x = "Year",
    y = "Total Monthly Crime Incidents",
  ) +
  theme(plot.title = element_text(hjust = 0.5))
```

There is incomplete data for `r temp <- crime_tsibble |> arrange(dates) |> as.data.frame() |> tail(1); temp |> dplyr::select(year) |> pull()`, as data were not provided after `r last_date <- temp |> dplyr::select(dates) |> pull(); paste0(month(last_date), "/", day(last_date), "/", year(last_date))`. 
<!-- This is hard-coded.. -->
We will omit any data after October 2016.

```{r}
#| code-fold: true
#| code-summary: "Show the code"

crime_monthly_ts1 <- crime_monthly_ts |>
  filter(months < yearmonth(mdy("11/1/2016")))
```

We apply Holt-Winters filtering on the monthly Baltimore crimes data with an additive model:

```{r}
#| code-fold: true
#| code-summary: "Show the code"

crime_hw <- crime_monthly_ts1 |>
  tsibble::fill_gaps() |>
  model(Additive = ETS(value ~
        trend("A") +
        error("A") +
        season("A"),
        opt_crit = "amse", nmse = 1))
report(crime_hw)
```

We can compute some values to assess the fit of the model:
```{r}
#| code-fold: true
#| code-summary: "Show the code"
#| eval: false

# SS of random terms
sum(components(crime_hw)$remainder^2, na.rm = T)

# RMSE
accuracy(crime_hw)$RMSE

# Standard devation of number of incidents each month
sd(crime_monthly_ts1$value)
```
-   The sum of the square of the random terms is: `r sum(components(crime_hw)$remainder^2, na.rm = T)`.
-   The root mean square error (RMSE) is: `r accuracy(crime_hw)$RMSE`.
-   The standard deviation of the number of incidents each month is `r sd(daily_summary_df$incidents)`.

@fig-crime-decomp illustrates the Holt-Winters decomposition of the Baltimore crime data.

```{r}
#| label: fig-crime-decomp
#| fig-cap: "Monthly Total Number of Crime Reported in Baltimore"
#| code-fold: true
#| code-summary: "Show the code"

autoplot(components(crime_hw))
```

In @fig-crime-hw, we can observe the relationship between the Holt-Winters filter and the time series of the number of crimes each month.

```{r}
#| label: fig-crime-hw
#| fig-cap: "Superimposed plots of the number of crimes each month and the Holt-Winters filter"
#| code-fold: true
#| code-summary: "Show the code"

augment(crime_hw) |>
  ggplot(aes(x = months, y = value)) +
    coord_cartesian(ylim = c(0,5500)) +
    geom_line() +
    geom_line(aes(y = .fitted, color = "Fitted")) +
    labs(color = "")
```

@fig-crime-hw-forecast contains the information from @fig-crime-hw, with the addition of an additional four years of forecasted values. The light blue bands give the 95% prediction bands for the forecast.

```{r}
#| label: fig-crime-hw-forecast
#| fig-cap: "Superimposed plots of the number of crimes each month and the Holt-Winters filter, with four additional years forecasted"
#| code-fold: true
#| code-summary: "Show the code"
#| warning: false

crime_forecast <- crime_hw |>
  forecast(h = "4 years") 
crime_forecast |>
  autoplot(crime_monthly_ts1, level = 95) +
  coord_cartesian(ylim = c(0,5500)) +
  geom_line(aes(y = .fitted, color = "Fitted"),
    data = augment(crime_hw)) +
  scale_color_discrete(name = "")
```

### Rethinking Baltimore

The monthly crime data shows a distinct pattern arcing through the annual cycle. 
Consider the data for 2011
```{r}
#| label: tbl-monthly-crimes-2011
#| tbl-cap: "Total count of crimes reported in Baltimore in 2011 by month"
#| echo: false

crime_monthly_ts1 |>
  as_tibble() |>
  filter(year(months) == 2011) |>
  mutate(months = month(months, label = TRUE)) |>
  pivot_wider(names_from = "months", values_from = "value") |>
  display_table()
```


<!-- Check Your Understanding -->

::: {.callout-tip icon=false title="Check Your Understanding"}

-   Starting with January, determine whether the number of crimes goes up or down as you move from one month to the next.
-   What might explain this pattern?
-   Use the function `days_in_month()` to adjust the time series and re-run the analysis. What do you notice?

:::











## Homework Preview (5 min)

-   Review upcoming homework assignment
-   Clarify questions


::: {.callout-note icon=false}

## Download Homework

<a href="https://byuistats.github.io/timeseries/homework/homework_3_3.qmd" download="homework_3_3.qmd"> homework_3_3.qmd </a>

:::












<a href="javascript:showhide('Solutions1')"
style="font-size:.8em;">BYU-Idaho Enrollment</a>

::: {#Solutions1 style="display:none;"}


@fig-enrollment-ts:

```{r}
#| warning: false
#| echo: false

enrollment_ts |>
  bind_rows(extra_terms) |>
  autoplot(.vars = enrollment) +
    labs(
      x = "Time",
      y = "Enrollment",
      title = paste0("BYU-Idaho On-Campus Enrollment Counts")
    ) +
    theme(
      plot.title = element_text(hjust = 0.5)
    )
```


@tbl-enrollment-table:

```{r}
#| warning: false
#| echo: false

enroll |>
  bind_rows(enroll_extension) |>
  mutate(
    est = case_when(
      row_number() == 1 ~ x_t,
      row_number() <= nrow(enroll) ~ a_t + s_t,
      TRUE ~ est
    )
  ) |>
  rename(
    "$$Semester$$" = semester,
    "$$t$$" = t,
    "$$x_t$$" = x_t,
    "$$a_t$$" = a_t,
    "$$b_t$$" = b_t,
    "$$s_t$$" = s_t,
    "$$\\hat x_t$$" = est
  ) |>
  convert_df_to_char(0) |>
  mutate(
    across(everything(), ~replace_na(.x, ""))
  ) |>
  display_table("0.75in")
```





:::

<a href="javascript:showhide('Solutions2')"
style="font-size:.8em;">Balitmore Crime Time Plot</a>

::: {#Solutions2 style="display:none;"}

```{r}
# Dates with high criminal activity
crime_data |> arrange(desc(incidents)) |> head()
```

On April 27, 2015, 419 crimes were recorded. These are associated with protests over arrest of Freddie Gray.


:::






## References

-   C. C. Holt (1957) Forecasting seasonals and trends by exponentially weighted moving averages, ONR Research Memorandum, Carnegie Institute of Technology 52. (Reprint at [https://doi.org/10.1016/j.ijforecast.2003.09.015](https://doi.org/10.1016/j.ijforecast.2003.09.015)).
-   P. R. Winters (1960). Forecasting sales by exponentially weighted moving averages. Management Science, 6, 324--342. (Reprint at [https://doi.org/10.1287/mnsc.6.3.324](https://doi.org/10.1287/mnsc.6.3.324).)