---
title: "Sample Statistics and Correlation"
subtitle: "Chapter 2"
format: html
editor: source
sidebar: false
number-sections: true
number-depth: 3  # Numbers only ## and ### headings
number-offset: 1
---

## Functions & Stuff

```{r}
#| echo: false
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
  # Interactive plots
  plotly, # Interactive visualizations, loaded before tidyverse so it overwrite dplyr::select(). Note: High conflict Potential

  # Core packages
  MASS, # MVNorm, loaded before tidyverse so it doesn't overwrite dplyr::select()
  tidyverse, # This will also load the dependencies; dplyr, readr, stringr, tibble, tidyr, purrr, forcats, gglot2, & lubridate

  # Data manipulation
  tsibble, # Tidyverse Temporal data
  tsibbledata, # Sample Tsibble datasets

  # Statistical modeling (GLS - Chpt 6-7)
  nlme, # loaded before feasts to avoid ACF() conflict
  tidymodels, # for GLS, This will also load the dependencies; broom, rsample, dials, tune, infer, workflows, modeldata, workflowsets, parsnip, yardstick, & recipies. Note: High conflict Potential
  multilevelmod, # for GLS
  broom.mixed, # for GLS

  # TS modeling and forecasting
  fable,# Forecasting Models for Tidy Time Series, Note: High conflict Potential
  feasts, # collection of features, decomposition methods, statistical summaries and graphics for tsibble data, Loaded after nlme to avoid ACF() conflict
  fable.prophet, # Converts prophet (forecasting) package for fable workflow

  # Data exploration & visualization
  patchwork, # Multiple plot outputs
  ggthemes, # Plot styling
  see,  # okabeito color scheme
  ggokabeito,  # colorblind palette

  # Reporting & output
  kableExtra, # Create nice-looking tables from data.frames
  rio, # Easy import/export of data between R and other software
  gt, # Grammar of Tables for advanced table creation
  quarto, # For generating reports in LaTeX format

  # Additional packages
  tidyquant # Quantitative analysis tools using tidyverse principles, This will also load the dependencies; PerformanceAnalytics, xts, & zoo. Important Masks: ‘package:base’: as.Date, as.Date.numeric. Note: High conflict Potential
)


okabeito_colors_list <- c(
  `orange` = "#E69F00",
  `light blue` = "#56B4E9",
  `green` = "#009E73",
  `yellow` = "#F0E442",
  `blue` = "#0072B2",
  `red` = "#D55E00",
  `purple` = "#CC79A7",
  `grey` = "#999999",
  `black` = "#000000",
  `sky blue` = "#56B4E9",
  `bluish green` = "#009E73",
  `vermillion` = "#D55E00",
  `reddish purple` = "#CC79A7",
  `dark yellow` = "#F5C710",
  `amber` = "#F5C710"
)


display_table <- function(df, min_col_width = "0in") {
  df |>
    knitr::kable(format = "html", align='ccccccccccccccccc', escape = FALSE, width = NA, row.names = FALSE) |>
    kable_styling(full_width = FALSE, "striped") |>
    column_spec(1:ncol(df), width_min = min_col_width)
}

round_df <- function(df, digits) {
  nums <- vapply(df, is.numeric, FUN.VALUE = logical(1))
  df[,nums] <- round(df[,nums], digits = digits)
  return(df)
}

convert_df_to_char <- function(df, decimals = 3) {
  out_df <- df |>
    as.data.frame() |>
    mutate_if(is.numeric, round, digits=decimals) |>
    mutate(across(everything(), as.character))
  return(out_df)
}

blank_out_cells_in_df <- function(df, ncols_to_keep = 2, nrows_to_keep = 0, decimals = 3) {
  out_df <- df |>
    convert_df_to_char(decimals)

  for (i in (nrows_to_keep + 1) : nrow(df))
    for (j in (ncols_to_keep + 1) : ncol(df)) {
      out_df[i,j] <- ""
    }
  return(out_df)
}

round_as_text <- function(x, places) {
  return(as.character(round(x,12)))
}

get_toy_data <- function(n = 10, mu = 0, sigma = 3, rho = 0.99, random_seed = 997) {
  set.seed(random_seed)

  # build population correlation matrix
  tmp.r <- matrix(rho, n, n)
  tmp.r <- tmp.r^abs(row(tmp.r)-col(tmp.r))

  return( round(mvrnorm(1, rep(mu,n), sigma^2 * tmp.r),1) )
}
```



```{=html}
<script type="text/javascript">
 function showhide(id) {
    var e = document.getElementById(id);
    e.style.display = (e.style.display == 'block') ? 'none' : 'block';
 }
 
 function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
 }    
</script>
```


# Chapter 2

(I known this looks funky, its a quarto numbering quirk, I assume the when we host through the school they will get around this with something more versatile.)

## Motivate the chapter. Why does it matter?

### Connect this with Ch1.1

## Differentiate population and sample properties and statistics

### Define population and samples

### Illustrate population and samples using pdf and histogram

## Contrast parameters and statistics, estimators and estimates

## Calculate a sample arithmetic mean

### Define expected value and sample mean

The expected value, also known as the population mean, represents the true average value of the entire population you're interested in. Unfortunately, obtaining the data for the entire population can be impractical or even impossible. This is where sample mean comes in.

```{r}
# Sample data
data <- data.frame(val=rnorm(200, 1.37))  # Generate 20 random numbers from a normal distribution

# Sample mean calculation
sample_mean <- mean(data$val)

# Print the sample mean
cat("Sample mean:", sample_mean, "\n")
```

### Explain the intuition of sample mean using a histogram

A histogram helps visualize the distribution of the data points in your sample. The sample mean, by definition, tends to be concentrated around the center of this distribution. The more data points you have in your sample, the closer the sample mean gets to the true expected value.

```{r}
# Histogram with sample mean highlighted
ggplot(data, aes(x = val)) +
  geom_histogram(bins = 15, color = "lightblue") +  # Adjust bin count as needed
  labs(x = "Data value", y = "Frequency", title = "Sample mean distribution") +
  geom_vline(xintercept = sample_mean, color = "red", linetype = "dashed", lwd = 2, label = "Sample Mean") +
  theme_classic()  # Optional: adjust plot aesthetics
```

By looking at the histogram, you can see how the data points tend to cluster around the sample mean, providing an intuition for how it estimates the true expected value of the population.

## Calculate a sample standard deviation

### Define population and sample variance standard deviation

### Explain the intuition behind the sample standard deviation using a histogram

### Explain a box and whiskers plot.

## Calculate sample covariance and correlation coefficient.

### Define covariance and sample covariance

### Explain the intuition of covariance using a scatter plot

### Define the correlation and sample correlation coefficient.

### Interpret an estimate of sample correlation coefficient.

## Calculate a sample autocorrelation

### Define population and sample autocorrelation

### Explain the intuition of sample autocorrelation using a scatter plot

### Interpret an estimate of sample autocorrelation at different lags

### Define a correlogram

### Conduct hypothesis testing using a correlogram

## Content Dump

#### Learning Outcomes

{{< include ../outcomes/new/_chapter_2_lesson_1_outcomes.qmd >}}

#### Preparation

-   Read Sections 2.1-2.2.2 and 2.2.4

#### Learning Journal Exchange (10 min)

-   Review another student's journal
-   What would you add to your learning journal after reading your partner's?
-   What would you recommend your partner add to their learning journal?
-   Sign the Learning Journal review sheet for your peer

#### Class Activity: Variance and Standard Deviation (10 min)

We will explore the variance and standard deviation in this section.

::: {.callout-tip icon="false" title="Check Your Understanding"}
-   What do the standard deviation and the variance measure?
:::

The following code simulates observations of a random variable. We will use these data to explore the variance and standard deviation.

```{r}
# Set random seed
set.seed(2412)

# Specify means and standard deviation
n <- 5        # number of points
mu <- 10      # mean
sigma <- 3    # standard deviation

# Simulate normal data
sim_data <- data.frame(x = round(rnorm(n, mu, sigma), 1)) |> 
  arrange(x)
```

```{r}
#| echo: false

# Convert to character string
# Initialize empty character vector
five_vals <- sim_data$x[1]
# Simulate normal data
for(t in 2:n){
  five_vals <- paste(five_vals, sim_data$x[t], sep=", ")
}
```

The data simulated by this process are:

<center>`r five_vals`</center>

::: {.callout-tip icon="false" title="Check Your Understanding"}
-   Find the sample mean of these numbers. <!-- `r mean(sim_data$x)`. -->
-   What are some ways to interpret the mean?
:::

The variance and standard deviation are individual numbers that summarize how far the data are from the mean. We first compute the deviations from the mean, $x - \bar x$. This is the directed distance from the mean to each data point.

```{r}
#| echo: false
#| warning: false
temp <- sim_data |> 
  mutate(deviations = x - mean(x)) |> 
  arrange(desc(x))

mean_x <- mean(temp$x)
min_x <- floor(min(temp$x))
max_x <- ceiling(max(temp$x))
range <- max_x - min_x
lower <- min_x - range / 10
upper <- max_x + range / 10

ticks <- ceiling(lower):floor(upper)
ticks_df <- data.frame(x = ticks, y = -1)


# Plot deviations from the mean
ggplot(temp, aes(x = x, y = 0)) +
  # x-axis
  annotate("segment", x = lower, xend = upper, y = -1, yend = -1, colour = "black", linewidth = 1, arrow = arrow(length = unit(0.3,"cm"))) +
  
  # Add tick marks and labels          
  annotate("segment", x = ticks, xend = ticks, y = -1.25, yend = -0.75, colour = "black", linewidth = 0.5) +

  geom_text(aes(x = upper, y = -1, label = "x"), size = 4, hjust = -1, vjust = 0, color = "black") +
  
  geom_text(data = ticks_df, aes(x = x, y = y, label = x), size = 4, vjust = 2, color = "black") +
  
  # Deviations from the mean arrows and lines
  geom_segment(aes(x = mean_x, xend = x, y = 1:n, yend = 1:n), colour = okabeito_colors_list[2], linewidth = 1, arrow = arrow(length = unit(0.3,"cm"))) +
  geom_segment(aes(x = x, xend = x, y = 0.25, yend = 1:n - 0.25), colour = okabeito_colors_list[2], linewidth = 0.5, linetype = "dashed") +
  geom_text(aes(x = (mean_x + x)/2, y = 1:n, label = round(deviations, 2)), size = 3, vjust = -0.5) +
  
  # Marker for the mean
  annotate("segment", x = mean_x, xend = mean_x, y = -2.5, yend = -1.25, colour = okabeito_colors_list[1], linewidth = 1, arrow = arrow(length = unit(0.3,"cm"))) +
  geom_segment(aes(x = mean_x, xend = mean_x, y = -0.75, yend = n + 1), colour = okabeito_colors_list[1], linewidth = 0.5, linetype = "dashed") +
  # Add xbar
  geom_label(
    label=expression(bar(x) == " "),
    x=mean_x-0.1,
    y=-2.6,
    color = okabeito_colors_list[1],parse = TRUE,label.size = NA, fill=NA)+
  # add mean value
  geom_label(
    label=paste0(round(mean_x, 2)),
    x=mean_x+0.3,
    y=-2.6,
    color = okabeito_colors_list[1],label.size = NA, fill=NA)+
  geom_point(size = 3, color = okabeito_colors_list[2]) + 
  geom_text(aes(x = x, y = rep(0,n), label = x), size = 3, vjust = 1.75) +
  
  # theme
  theme_void() +
  theme(axis.title.y = element_blank()) +
  theme(plot.title = element_text(hjust = 0.5)) +
     
  theme(aspect.ratio = 0.4) +
  labs(title = "Deviations from the Mean", 
       x = "Value",
       y = "")
```

We can summarize this information in a table:

######## Table 1: Deviations from the mean

```{r}
#| echo: false
sim_data |> 
  mutate(
    xx = x - mean(x),
    extra1 = " ",
    extra2 = " ",
    extra3 = " ",
    extra4 = " "
    ) |> 
  rename(
    "$$x_t$$" = x,
    "$$x_t-\\bar x$$" = xx,
    " " = extra1,
    "  " = extra2,
    "   " = extra3,
    "    " = extra4
  ) |>
  display_table("0.75in")
```

::: {.callout-tip icon="false" title="Check Your Understanding"}
How can we obtain one number that summarizes how spread out the data are from the mean? We may try averaging the deviations from the mean.

-   What is the average deviation from the mean?
-   Will we get the same value with other data sets, or is this just a coincidence?
-   What could you do to prevent this from happening?
-   Apply your idea. Compute the resulting value that summarizes the spread. What do you get?
-   What is the relationship between the sample variance and the sample standard deviation?
-   Use a table like the one above to verify that the sample variance is `r var(sim_data$x)`.
-   Show that the sample standard deviation is `r sd(sim_data$x) |> round(4)`.
:::

#### Class Activity: Covariance and Correlation (15 min)

```{=html}
 <iframe id="CoAndCo" src="https://posit.byui.edu/content/564c2e71-3d0b-43a6-8c6f-d402125c8b28" style="border: none; width: 100%; height: 2200px" frameborder="0"></iframe>
```
::: {.callout-tip icon="false" title="Check Your Understanding"}
-   What do you get if you multiply the equations for $r$, $s_x$, and $s_y$ together?
:::

$$
  r \cdot s_x \cdot s_y 
    =
      \frac{\sum\limits_{t=1}^n (x - \bar x)(y - \bar y)}{\sqrt{\sum\limits_{t=1}^n (x - \bar x)^2} \sqrt{\sum\limits_{t=1}^n (y - \bar y)^2}} 
      \cdot 
      \sqrt{ \frac{\sum\limits_{t=1}^n (x - \bar x)^2}{n-1} }
      \cdot 
      \sqrt{ \frac{\sum\limits_{t=1}^n (y - \bar y)^2}{n-1} }
    =
      ?
$$

::: {.callout-tip icon="false" title="Check Your Understanding"}
-   Use the numerical values above to confirm your result. Any discrepancy is due to roundoff error.
:::

#### Team Activity: Computational Practice (15 min)

```{r}
#| echo: false

# Set random seed
set.seed(300)

# Specify means and correlation coefficient
n <- 6              # number of points
mu <- c(3, 1)       # mean vector (mu_x, mu_y)
sigma_x <- 3.5      # standard deviation x
sigma_y <- 2        # standard deviation y
rho <- -0.85          # correlation coefficient

# Define variance-covariance matrix
sigma <- matrix(
  c(sigma_x^2,
    rho*sigma_x*sigma_y,
    rho*sigma_x*sigma_y,
    sigma_y^2),
  nrow = 2)

# Simulate bivariate normal data
mvn_data_6 <- MASS::mvrnorm(n, mu, sigma) |> 
  data.frame() |> 
  rename(x = X1, y = X2) |> 
  round_df(1)
```

######## Table 3: Computational Practice

The table below contains values of two time series $\{x_t\}$ and $\{y_t\}$ observed at times $t = 1, 2, \ldots, 6$. We will use these values to practice finding the means, standard deviations, correlation coefficient, and covariance without using built-in R functions.

```{r}
#| echo: false

cov_dat <- mvn_data_6 |> 
  mutate(t = row_number()) |> 
  dplyr::select(t, x, y) |> 
  mutate(
    xx = x - mean(x),
    xx2 = xx^2,
    yy = y - mean(y),
    yy2 = yy^2,
    xy = (x - mean(x)) * (y - mean(y))
    ) 

cov_dat_summary <- cov_dat |> 
  summarize(
    x = sum(x),
    y = sum(y),
    xx = sum(xx),
    xx2 = sum(xx2),
    yy = sum(yy),
    yy2 = sum(yy2),
    xy = sum(xy)
  ) |> 
  round_df(5) |>
  mutate(across(everything(), as.character)) |> 
  mutate(t = "sum")

temp <- cov_dat |> 
  round_df(5) |>
  mutate(across(everything(), as.character)) |> 
  bind_rows(cov_dat_summary)

temp |> 
  blank_out_cells_in_df(ncols_to_keep = 3, nrows_to_keep = 1) |>
  bind_rows(temp |> tail(1) |> blank_out_cells_in_df(ncols_to_keep = 0, nrows_to_keep = 0) |> mutate(t = "$$~$$")) |> 
  rename(
    "$$t$$" = t,
    "$$x_t$$" = x,
    "$$y_t$$" = y,
    "$$x_t-\\bar x$$" = xx, 
    "$$(x_t - \\bar x)^2$$" = xx2, 
    "$$y_t-\\bar y$$" = yy,
    "$$(y_t-\\bar y)^2$$" = yy2, 
    "$$(x_t - \\bar x)(y_t-\\bar y)$$" = xy
  ) |>
  display_table()
```

Use the table above to determine these values:

::: columns
::: {.column width="30%"}
-   $\bar x =$

-   $\bar y =$
:::

::: {.column width="5%"}
<!-- empty column to create gap -->
:::

::: {.column width="30%"}
-   $s_x =$

-   $s_y =$
:::

::: {.column width="5%"}
<!-- empty column to create gap -->
:::

::: {.column width="30%"}
-   $r =$

-   $\\cov(x,y) =$
:::
:::

Here is a scatterplot of the data.

<center>

```{r fig.asp=0.75}
#| echo: false
#| warning: false

cov_dat <- cov_dat |> 
  mutate(
    sign = case_when(
      xy > 0 ~ "positive", 
      xy < 0 ~ "negative",
      TRUE ~ "zero")
  ) 
  
ggplot(cov_dat, aes(x = x, y = y)) +
  geom_point(size = 2) +
  labs(x="x", y="y") +
  theme_bw() +  
  ggtitle(paste0("Data for Computational Practice (n = ",n,")")) + 
  theme(plot.title = element_text(hjust = 0.5)) 
```

</center>

##### Summary

::: {.callout-tip icon="false" title="Check Your Understanding"}
Working with your partner, prepare to explain the following concepts to the class:

-   Variance
-   Standard deviation
-   Correlation
-   Covariance
:::

#### Computations in R (5 min)

Use these commands to load the data from the previous activity into R.

```{r}
#| echo: false
x <- mvn_data_6$x
y <- mvn_data_6$y
cat("x <- c(", paste(mvn_data_6$x, collapse = ", "),")")
cat("y <- c(", paste(mvn_data_6$y, collapse = ", "),")")
```

We can use R to compute the mean, variance, standard deviation, correlation coefficient, and covariance.

######## Mean, $\bar x$

```{r}
mean(x)
```

######## Variance, $s_x^2$

```{r}
var(x)
```

######## Standard Deviation, $s_x$

```{r}
sd(x)
```

######## Correlation Coefficient, $r$

```{r}
cor(x, y)
```

######## Covariance, $\\cov(x,y)$

```{r}
cov(x, y)
```

<a href="javascript:showhide('Solutions')"
style="font-size:.8em;">Class Activity: Variance and Standard Deviation</a>

::: {#Solutions style="display:none;"}
Solutions to Class Activity: Variance and Standard Deviation

```{r}
#| echo: false
temp <- sim_data |> 
  mutate(
    xx = x - mean(x),
    xx2 = (x - mean(x))^2,
    ) 

temp2 <- temp |> 
  bind_rows(colSums(temp)) |>
  round_df(5) |>
  mutate(Solution = ifelse(row_number() == n(), "Sum", "")) |>
  dplyr::select(Solution, x, xx, xx2) |>
  data.frame()

ssx <- temp2[nrow(temp2), ncol(temp2)]

temp2 |> 
  rename(
    "$$x_t$$" = x,
    "$$x_t-\\bar x$$" = xx, 
    "$$(x_t-\\bar x)^2$$" = xx2
  ) |>
  display_table()
```

```{r}

```

The variance of these values is $s^2 = \frac{`r ssx`}{`r nrow(temp)` - 1} = `r var(x)`$.

The standard deviation is $s = \sqrt{s^2} = \sqrt{`r var(x)`} = `r sd(x) |> round(3)`$.
:::

<a href="javascript:showhide('Solutions2')"
style="font-size:.8em;">Team Activity: Computational Practice</a>

::: {#Solutions2 style="display:none;"}
Solutions to Team Activity: Computational Practice

######## Table 3: Computational Practice

```{r}
#| echo: false

cov_dat <- mvn_data_6 |> 
  mutate(t = row_number()) |> 
  dplyr::select(t, x, y) |> 
  mutate(
    xx = x - mean(x),
    xx2 = xx^2,
    yy = y - mean(y),
    yy2 = yy^2,
    xy = (x - mean(x)) * (y - mean(y))
    ) 

cov_dat_summary <- cov_dat |> 
  summarize(
    x = sum(x),
    y = sum(y),
    xx = sum(xx),
    xx2 = sum(xx2),
    yy = sum(yy),
    yy2 = sum(yy2),
    xy = sum(xy)
  ) |> 
  round_df(5) |>
  mutate(across(everything(), as.character)) |> 
  mutate(t = "sum")

temp <- cov_dat |> 
  round_df(5) |>
  mutate(across(everything(), as.character)) |> 
  bind_rows(cov_dat_summary)

temp |> 
  # blank_out_cells_in_df(ncols_to_keep = 3, nrows_to_keep = 1) |>
  # bind_rows(temp |> tail(1) |> blank_out_cells_in_df(ncols_to_keep = 0, nrows_to_keep = 0) |> mutate(t = "$$~$$")) |> 
  rename(
    "$$t$$" = t,
    "$$x_t$$" = x,
    "$$y_t$$" = y,
    "$$x_t-\\bar x$$" = xx, 
    "$$(x_t - \\bar x)^2$$" = xx2, 
    "$$y_t-\\bar y$$" = yy,
    "$$(y_t-\\bar y)^2$$" = yy2, 
    "$$(x_t - \\bar x)(y_t-\\bar y)$$" = xy
  ) |>
  display_table()
```

::: columns
::: {.column width="30%"}
-   $\bar x = `r mean(mvn_data_6$x)`$

-   $\bar y = `r mean(mvn_data_6$y)`$
:::

::: {.column width="5%"}
<!-- empty column to create gap -->
:::

::: {.column width="30%"}
-   $s_x = `r sd(mvn_data_6$x)`$

-   $s_y = `r sd(mvn_data_6$y)`$
:::

::: {.column width="5%"}
<!-- empty column to create gap -->
:::

::: {.column width="30%"}
-   $r = `r cor(mvn_data_6$x, mvn_data_6$y)`$

-   $\\cov(x,y) = `r cov(mvn_data_6$x, mvn_data_6$y)`$
:::
:::
:::

### New section 1

```{r}
#| include: false

get_data_for_cov_table <- function(offset = 1) {
  # set random number generator seed
  set.seed(997)
  
  # set parameters
  n <- 10
  rho <- 0.99
  mu <- 0
  sigma <- 3
  
  # build population correlation matrix
  tmp.r <- matrix(rho, n, n)
  tmp.r <- tmp.r^abs(row(tmp.r)-col(tmp.r))
  
  # simulate correlated normal random data
  x1 <- round(mvrnorm(1, rep(mu,n), sigma^2 * tmp.r),1) 
  
  # build a data frame
  df <- data.frame(t = 1:length(x1),
                   x = x1,
                   y = lead(x1, offset)) %>%
    mutate(
      xx = x - mean(x),
      xx2 = xx^2,
      yy = y - mean(x),
      # yy2 = yy^2,
      xy = xx * yy
    ) %>% 
    dplyr::select(t, x, y, xx, xx2, yy, xy)
  
  return(df)
}

make_cov_table_df <- function(df, offset=1, decimals_1st_order = 5, decimals_2nd_order = 5) {
  # Color vector
  oi_colors <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#F5C710", "#CC79A7", "#999999")
  
  df_summary <- df %>% 
    summarize(
      x = sum(x),
      y = sum(y, na.rm = TRUE),
      xx = sum(xx),
      yy = sum(yy, na.rm = TRUE),
      xx2 = sum(xx2),
      # yy2 = sum(yy2, na.rm = TRUE),
      xy = sum(xy, na.rm = TRUE)
    ) %>% 
    # round_df(3) %>% 
    mutate(t = paste0("sum")) %>% 
    mutate(
      t = paste0("sum"),
      x = round_as_text(x, 1),
      y = round_as_text(y, 1),
      xx = round_as_text(xx, decimals_1st_order),
      xx2 = round_as_text(xx2, decimals_2nd_order),
      yy = round_as_text(yy, decimals_1st_order),
      # yy2 = round_as_text(yy2, decimals_2nd_order),
      xy = round_as_text(xy, decimals_2nd_order)
    ) %>% 
    dplyr::select(t, x, y, xx, xx2, yy, xy)
  
  out <- df %>%
    mutate(
      t = as.character(t),
      x = round_as_text(x, 1),
      y = round_as_text(y, 1),
      xx = round_as_text(xx, decimals_1st_order),
      xx2 = round_as_text(xx2, decimals_2nd_order),
      yy = round_as_text(yy, decimals_1st_order),
      # yy2 = round_as_text(yy2, decimals_2nd_order),
      xy = round_as_text(xy, decimals_2nd_order)
    ) %>% 
    mutate(
      x = cell_spec(x, 
                    color = case_when(
                      is.na(x) ~ "#999999",
                      TRUE ~ oi_colors[( row_number() + 0 ) %% 9 + 1]
                    )
      ),
      y = cell_spec(y, 
                    color = case_when(
                      is.na(y) ~ "#999999",
                      TRUE ~ oi_colors[( row_number() + offset ) %% 9 + 1]
                    )
      )
    ) %>% 
    mutate(
      # x = ifelse(row_number() > nrow(.) - offset, paste0("[",x,"]"), x),
      y = ifelse(row_number() > nrow(.) - offset, NA, y),
    ) %>% 
    replace(., is.na(.), "—") %>%
    bind_rows(df_summary) %>% 
    rename(
      "x_t" = x,
      "x_{t+k}" = y,
      # paste0("x_{t+", offset, "}") = y,
      "x_t-mean(x)" = xx, 
      "(x_t-mean(x))^2" = xx2, 
      "x_{t+k}-mean(x)" = yy,
      # "(x_{t+k}-mean(x))^2" = yy2, 
      "(x-mean(x))(x_{t+k}-mean(x))" = xy
    )
  
  return(out)
}

# Eliminates the values in columns 3 onward for a specified row_num
make_blank_row_in_cov_table <- function(df, row_num) {
  for (col_num in 3:ncol(df)) {
    df[row_num, col_num] = ""
  }
  return(df)
}

# Compute summary values
compute_summaries <- function(df, digits = 4) {
  df %>% 
    summarize(
      n = n(),
      mean_x = mean(x),
      mean_y = mean(y, na.rm = TRUE),
      ss_x = sum(xx2),
      # ss_y = sum(yy2, na.rm = TRUE),
      ss_xy = sum(xy, na.rm = TRUE),
      c_0 = sum(xx2) / nrow(.),
      c_k = sum(xy, na.rm = TRUE) / nrow(.),
      r_k = c_k / c_0
    ) %>% 
    round_df(digits)
}

```


#### Learning Outcomes

{{< include ../outcomes/_chapter_2_lesson_2_outcomes.qmd >}}




#### Preparation

-   Read Sections 2.2.5 and 2.3-2.5


#### Learning Journal Exchange (10 min)

-   Review another student's journal
-   What would you add to your learning journal after reading your partner's?
-   What would you recommend your partner add to their learning journal?
-   Sign the Learning Journal review sheet for your peer


#### Hands-on Exercise -- Exploring Sample Autocorrelation (40 min)

<!-- Compute sample acvf and acf -->

##### Comparison of Independent and Autocorrelated Error Terms

In the previous lesson, we computed the sample covariance and sample correlation coefficient between two independent variables. When working with time series, the observations are not independent. There is often a relationship between sequential observations. We will compute the autocovariance function and autocorrelation function for a time series. Note: the prefix "auto" comes from a Greek root meaning "self."

The figure below illustrates the difference between a series of data, where the residuals are independent compared to a series with autocorrelated data.

```{r}
#| echo: false 

# Generate data
set.seed(101) 
x <- 1:100*0.5 + arima.sim(n=100-1, list(ar=0.1, ma=0.2, order=c(1,1,1)))
e <- rnorm(100, 0, 2.5)
y <- 1:100*0.5 + e  

# Create data frame  
df <- data.frame(
  time = 1:100,
  Autocorrelated = x,
  Independent = y
)

# Plot  
ggplot(df, aes(x = time)) +
  geom_line(aes(y = Independent, color = "Independent")) + 
  geom_point(aes(y = Independent, color = "Independent")) + 
  geom_line(aes(y = Autocorrelated, color = "Autocorrelated")) + 
  geom_point(aes(y = Autocorrelated, color = "Autocorrelated")) +
  scale_color_okabeito(
    palette = "full",
    reverse = FALSE,
    order = c(2,4),
    aesthetics = "color"
  ) +
  labs(title="Comparison of Independent and Autocorrelated Error Terms", 
       x="Time",
       y="Values",
       color="Series") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```

::: {.callout-tip icon=false title="Check Your Understanding"}

-   The variances of the residuals for these two series are approximately equal. What characteristics distinguish the two series in the figure above?

:::

##### Autocovariance and Autocorrelation 

We will use the following data to explore the concepts of autovariance and autocorrelation.

```{r}
#| echo: false

offset_value <- 1
cov_df <- get_data_for_cov_table(offset = offset_value)

# Obtain the number of data values.
n <- nrow(cov_df)


cov_df %>%
  dplyr::select(t, x) %>% 
  rename("$$ x_t $$"= x) %>% 
  display_table()
```

You can use this R command to read in the observations.

```{r}
#| echo: false

cat("x <- c(", paste(cov_df$x, collapse = ", "),")")
```

```{r}
#| echo: false

ggplot(cov_df, aes(x = t, y = x)) +
  geom_line(color = "#0072B2") +
  geom_point(color = "#0072B2") +
#   scale_color_okabeito(
#   palette = "full",
#   reverse = TRUE,
#   order = c(1,7,8,5,6,3,4,2,9),
#   aesthetics = "color"
# ) +
  ylim(0,ceiling(max(cov_df$x))) +
  labs(title = "Sample Time Series",
       x = "Time",
       y = "x") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) 
```

We will use the sample mean of these data repeatedly. The value of $\bar x$ is:

$$
  \bar x 
    = \frac{1}{n} \sum\limits_{t=1}^{n} x_t 
    = \frac{1}{`r n`} \cdot `r sum(cov_df$x) %>% round(4)`
    = `r mean(cov_df$x)`
$$


We will be finding the autocovariance and correlation of a time series with itself. First, we start with a lag of 1. With a lag of 1 the corresponding values of the time series that are being compared are shifted by one time unit. Then, we will consider any integer lag: lag $k$.


##### Lag $k$ Sample Autocovariance Function (acvf), $c_k$

The **lag** $k$ sample autocovariance function, acvf, denoted $c_k$, is defined as

$$
  c_k = \frac{1}{n} \sum\limits_{t=1}^{n-k}(x_t-\bar x)(x_{t+k}-\bar x)
$$

We denote the lag by the letter $k$, where $k \ge 0$. This is the number of values the data set is shifted to compute the autocovariance.

::: {.callout-tip icon=false title="Check Your Understanding"}

-   Explain the equation for $c_k$ to your partner.
-   What is the equation for $c_0$, the value of the autocovariance function with lag $k=0$?
    -   This expression is very similar to a definition we have encountered previously. What is it?

:::


######## Lag $k=1$ Sample Autocovariance Function, $c_1$

We will now find the autocovariance between the values in a time series ($x = x_t$) and the same values, shifted by one unit of time ($y = x_{t+1}$).

```{r}
#| echo: false
offset_value <- 1
cov_df <- get_data_for_cov_table(offset = offset_value)
cov_table <- cov_df %>%
  make_cov_table_df(offset = offset_value)#, decimals_1st_order = 1, decimals_2nd_order = 2) 
summarized <- compute_summaries(cov_df)
cov_table %>%
  rename(
    "$$ x_t $$" = x_t,
    "$$ x_{t+k} $$" = `x_{t+k}`,
    "$$ x_t-\\bar x $$" = `x_t-mean(x)`,
    "$$ (x_t-\\bar x)^2 $$" = `(x_t-mean(x))^2`,
    "$$ x_{t+k}-\\bar x$$"= `x_{t+k}-mean(x)`,
    "$$ (x-\\bar x)(x_{t+k}-\\bar x) $$"= `(x-mean(x))(x_{t+k}-mean(x))`
  ) %>% 
  display_table()
```

::: {.callout-tip icon=false title="Check Your Understanding"}

-   Working with your assigned partner, compute each of the values in row 1 by hand.  Recall that $\bar x = `r mean(cov_df$x)`$.
-   With your partner, add up the values in the last column to verify that the sum is `r sum(cov_df$xy, na.rm = TRUE) %>% round(10)`.

:::

The scatterplot below illustrates the relationship between the observed data ($x_t$) and the next observation ($x_{t+1}$).

```{r}
#| echo: false

ggplot(cov_df %>% na.omit(), aes(x = x, y = y)) +
  geom_point(size = 2, colour= "#0072B2") +
  xlab(expression(x[t])) +
  ylab(expression(x[t+1])) +
  theme_bw() +  
  ggtitle(paste0("Data pairs with a lag of k=",offset_value)) + 
  theme(plot.title = element_text(hjust = 0.5)) 
```

In this example, the second variable is $x_{t+1}$, where $t>1$. the autocovariance of $x_t$ and $x_{t+1}$ is:

$$
  c_1 
    = \frac{1}{n} \sum\limits_{t=1}^{n-1}(x_t-\bar x)(x_{t+1}-\bar x)
    = \frac{1}{`r n`} \sum\limits_{t=1}^{`r n - offset_value`}(x_t-\bar x)(x_{t+1}-\bar x)
  = \frac{1}{`r n`} \cdot `r summarized$ss_xy`
  = `r summarized$c_k`
$$

This is the (auto)covariance of $x$ with itself, but with a lag of 1 time unit. This is the value of the **lag** $k=1$ autocovariance function, acvf_1.

::: {.callout-tip icon=false title="Check Your Understanding"}

-   What does the lag 1 autocovariance measure?

:::

##### Lag $k$ Sample Autocorrelation Function (acf), $r_k$

The **sample autocorrelation function, acf**, denoted $r_k$, where $k$ is the lag, is defined as

$$
  r_k 
    = \frac{c_k}{c_0} 
    = \frac{ \frac{1}{n} \sum\limits_{t=1}^{n-k}(x_t-\bar x)(x_{t+k}-\bar x) }{ \frac{1}{n} \sum\limits_{t=1}^{n}(x_t-\bar x)^2 }
    = \frac{ \sum\limits_{t=1}^{n-k}(x_t-\bar x)(x_{t+k}-\bar x) }{ \sum\limits_{t=1}^{n}(x_t-\bar x)^2 }
$$

Note that $c_0$ is the variance of $x$, but computed by dividing by $n$, instead of $n-1$.

::: {.callout-tip icon=false title="Check Your Understanding"}

-   Interpret the components of the numerator and the denominator of the expression for $r_k$ to your partner.

:::

######## Lag $k=1$ Sample Autocorrelation Function, $r_1$

We can compute the **lag 1 autocorrelation** or the **autocorrelation of** $x$ with lag 1 as the quotient $r_1 = \frac{c_1}{c_0}$. We have already determined that 
$c_1 = `r summarized$c_k %>% round(4)`$. We now compute $c_0$:

$$ 
  c_0 = \frac{1}{n} \sum\limits_{t=1}^{n-0} (x_t-\bar x)(x_{t+0}-\bar x) 
    = \frac{1}{n} \sum\limits_{t=1}^{n} (x_t-\bar x)^2
    = \frac{1}{`r n`} \cdot `r summarized$ss_x %>% round(4)`
    = `r summarized$c_0 %>% round(4)`
$$

We use $c_0$ and $c_1$ to compute $r_1$. Here are two ways we can compute this value:

\begin{align*}
  r_1
    &= \frac{c_1}{c_0} 
    =
    \frac{ \frac{1}{n} \sum\limits_{t=1}^{`r n - offset_value`}(x_t-\bar x)(x_{t+1}-\bar x)
        }{
            \frac{1}{n} \sum\limits_{t=1}^{`r n`}(x_t-\bar x)^2
        }  
    =
    \frac{
        \frac{1}{`r summarized$n`} \cdot `r summarized$ss_xy`
      }{
        \frac{1}{`r summarized$n`} \cdot `r summarized$ss_x`
      }
    = \frac{`r summarized$c_k`}{`r summarized$c_0`}
    = `r summarized$r_k %>% round(4)`
    \\
    &=
    \frac{ \sum\limits_{t=1}^{`r n - offset_value`}(x_t-\bar x)(x_{t+1}-\bar x)
        }{
           \sum\limits_{t=1}^{`r n`}(x_t-\bar x)^2
        }  
    = \frac{`r summarized$ss_xy`}{`r summarized$ss_x`}
    = `r summarized$r_k %>% round(4)`
    
\end{align*}

-   What does the lag 1 autocorrelation, $c_1$, measure?

```{r}
#| echo: false

# Initialize table
auto_cov_cor_table <- data.frame(lag = integer(),
                  autocovariance = double(),
                  autocorrelation = double())
```

```{r}
#| echo: false

# Add rows to the table
auto_cov_cor_table <- auto_cov_cor_table %>% 
  bind_rows(c(
    lag = offset_value, 
    autocovariance = summarized$c_k, 
    autocorrelation = summarized$r_k
    )
  )

# # Display the table, except row 2
# auto_cov_cor_table %>%
#   mutate( ############################################################################# Suppresses row 2
#     autocovariance = ifelse(row_number() == 2,"", autocovariance),
#     autocorrelation = ifelse(row_number() == 2,"", autocorrelation)
#   ) %>% 
#   knitr::kable(format = "html", align='ccc', escape = FALSE, width = NA) %>%
#   kable_styling(full_width = FALSE, "striped") 
```

######## Lag $k = 2$

::: {.callout-tip icon=false title="Check Your Understanding"}

-   Working with your assigned partner, fill in the blanks in the following table. Use the results to compute $c_2$ and $r_2$.

:::

```{r}
#| echo: false
offset_value <- 2
cov_df <- get_data_for_cov_table(offset = offset_value)
cov_table <- cov_df %>%
  make_cov_table_df(offset = offset_value)#, decimals_1st_order = 1, decimals_2nd_order = 2) 
summarized <- compute_summaries(cov_df)
cov_table %>%
    rename(
    "$$ x_t $$" = x_t,
    "$$ x_{t+k} $$" = `x_{t+k}`,
    "$$ x_t-\\bar x $$" = `x_t-mean(x)`,
    "$$ (x_t-\\bar x)^2 $$" = `(x_t-mean(x))^2`,
    "$$ x_{t+k}-\\bar x$$"= `x_{t+k}-mean(x)`,
    "$$ (x-\\bar x)(x_{t+k}-\\bar x) $$"= `(x-mean(x))(x_{t+k}-mean(x))`
  ) %>%
  ######################## Let students fill in these rows ####################
  make_blank_row_in_cov_table(4) %>% 
  make_blank_row_in_cov_table(5) %>% 
  make_blank_row_in_cov_table(6) %>%
  make_blank_row_in_cov_table(11) %>% 
  display_table()
```

The figure below illustrates the relationship between $x_t$ and $x_{t+2}$.

```{r}
#| echo: false

ggplot(cov_df %>% na.omit(), aes(x = x, y = y)) +
  geom_point(size = 2, colour= "#0072B2") +
  xlab(expression(x[t])) +
  ylab(expression(x[t+2])) +
  theme_bw() +
  ggtitle(paste0("Data pairs with a lag of k=",offset_value)) +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
#| echo: false

# Add rows to the table
auto_cov_cor_table <- auto_cov_cor_table %>% 
  bind_rows(c(
    lag = offset_value, 
    autocovariance = summarized$c_k, 
    autocorrelation = summarized$r_k
    )
  )
```

######## Lag $k = 3$

```{r}
#| echo: false
offset_value <- 3
cov_df <- get_data_for_cov_table(offset = offset_value)
cov_table <- cov_df %>%
  make_cov_table_df(offset = offset_value)#, decimals_1st_order = 1, decimals_2nd_order = 2) 
summarized <- compute_summaries(cov_df)
cov_table %>%
    rename(
    "$$ x_t $$" = x_t,
    "$$ x_{t+k} $$" = `x_{t+k}`,
    "$$ x_t-\\bar x $$" = `x_t-mean(x)`,
    "$$ (x_t-\\bar x)^2 $$" = `(x_t-mean(x))^2`,
    "$$ x_{t+k}-\\bar x$$"= `x_{t+k}-mean(x)`,
    "$$ (x-\\bar x)(x_{t+k}-\\bar x) $$"= `(x-mean(x))(x_{t+k}-mean(x))`
  ) %>%
  display_table()
```

The figure below illustrates the correlations between $x_t$ and $x_{t+3}$. Note that $c_3 = \dfrac{`r summarized$ss_xy`}{`r summarized$n`} = `r summarized$c_k`$ and  $r_3 = \dfrac{`r summarized$c_k`}{`r summarized$c_0`} = `r summarized$r_k`$.

::: {.callout-tip icon=false title="Check Your Understanding"}

-   Does the value of $r_3 = `r summarized$r_k`$ seem reasonable, given the pattern in this plot?

:::

```{r}
#| echo: false

ggplot(cov_df %>% na.omit(), aes(x = x, y = y)) +
  geom_point(size = 2, colour= "#0072B2") +
  xlab(expression(x[t])) +
  ylab(expression(x[t+3])) +
  theme_bw() +  
  ggtitle(paste0("Data pairs with a lag of k=",offset_value)) + 
  theme(plot.title = element_text(hjust = 0.5)) 
```

```{r}
#| echo: false

# Add rows to the table
auto_cov_cor_table <- auto_cov_cor_table %>% 
  bind_rows(c(
    lag = offset_value, 
    autocovariance = summarized$c_k, 
    autocorrelation = summarized$r_k
    )
  )
```

######## Lag $k = 4$

::: {.callout-tip icon=false title="Check Your Understanding"}

-   Compute $c_4$ and $r_4$ using R (but not automated functions), Excel, or hand calculations.

:::

```{r}
#| echo: false
offset_value <- 4
cov_df <- get_data_for_cov_table(offset = offset_value)
cov_table <- cov_df %>%
  make_cov_table_df(offset = offset_value)#, decimals_1st_order = 1, decimals_2nd_order = 2) 
summarized <- compute_summaries(cov_df)
cov_table %>%
    rename(
    "$$ x_t $$" = x_t,
    "$$ x_{t+k} $$" = `x_{t+k}`,
    "$$ x_t-\\bar x $$" = `x_t-mean(x)`,
    "$$ (x_t-\\bar x)^2 $$" = `(x_t-mean(x))^2`,
    "$$ x_{t+k}-\\bar x$$"= `x_{t+k}-mean(x)`,
    "$$ (x-\\bar x)(x_{t+k}-\\bar x) $$"= `(x-mean(x))(x_{t+k}-mean(x))`
  ) %>%
  make_blank_row_in_cov_table(1) %>% 
  make_blank_row_in_cov_table(2) %>%  
  make_blank_row_in_cov_table(3) %>%  
  make_blank_row_in_cov_table(4) %>%  
  make_blank_row_in_cov_table(5) %>%  
  make_blank_row_in_cov_table(6) %>%  
  make_blank_row_in_cov_table(7) %>%  
  make_blank_row_in_cov_table(8) %>%  
  make_blank_row_in_cov_table(9) %>%  
  make_blank_row_in_cov_table(10) %>%  
  make_blank_row_in_cov_table(11) %>% 
  display_table()
```


The figure below illustrates the correlations between $x_t$ and $x_{t+4}$.

::: {.callout-tip icon=false title="Check Your Understanding"}

-   Does the value of $r_4$ you computed seem reasonable, given the pattern in this plot?

:::

```{r}
#| echo: false

ggplot(cov_df %>% na.omit(), aes(x = x, y = y)) +
  geom_point(size = 2, colour= "#0072B2") +
  xlab(expression(x[t])) +
  ylab(expression(x[t+4])) +
  theme_bw() +  
  ggtitle(paste0("Data pairs with a lag of k=",offset_value)) + 
  theme(plot.title = element_text(hjust = 0.5)) 
```

#### Class Activity: Using R to compute the acvf and acf (5 min)

We will continue to use the following sample data.

```{r}
#| echo: false

# simulate correlated normal random data
x1 <- get_toy_data()
df <- data.frame(x = x1)

cat(" x <- c(",paste(x1, collapse = ", "),") \n df <- data.frame(x = x)")
```

##### acvf

This code gives the values of the acvf.

```{r}
acf(df$x, plot=FALSE, type = "covariance")
```


##### acf

We can obtain the acf by changing the argument for the paramter `type` to `"correlation"`.

```{r}
acf(df$x, plot=FALSE, type = "correlation")
```




#### Homework Preview (5 min)

-   Review upcoming homework assignment
-   Clarify questions



#### Homework

::: {.callout-note icon=false}

#### Download Homework

<a href="https://byuistats.github.io/timeseries/homework/homework_2_2.qmd" download="homework_2_2.qmd"> homework_2_2.qmd </a>

:::

<a href="javascript:showhide('Solutions')"
style="font-size:.8em;">Class Activity: k=2</a>

::: {#Solutions style="display:none;"}

Solutions to Class Activity: $k=2$

```{r}
#| echo: false
offset_value <- 2
cov_df <- get_data_for_cov_table(offset = offset_value)
cov_table <- cov_df %>%
  make_cov_table_df(offset = offset_value)#, decimals_1st_order = 1, decimals_2nd_order = 2) 
summarized <- compute_summaries(cov_df)
cov_table %>%
  display_table()
```

\begin{align*}
  c_2
    &= \frac{1}{n} \sum\limits_{t=1}^{n-1}(x_t-\bar x)(x_{t+2}-\bar x)
    = \frac{1}{`r n`} \cdot `r summarized$ss_xy`
    = `r summarized$c_k |> round(3)` \\
  r_2 
    &= \frac{c_2}{c_0} 
    = \frac{`r summarized$c_k |> round(3)`}{`r summarized$c_0 |> round(3)`} 
    = `r summarized$r_k |> round(3)`
\end{align*}

:::

<a href="javascript:showhide('Solutions_k4')"
style="font-size:.8em;">Class Activity: k=4</a>

::: {#Solutions_k4 style="display:none;"}

Solutions to Class Activity: $k=4$


```{r}
#| echo: false
offset_value <- 4
cov_df <- get_data_for_cov_table(offset = offset_value)
cov_table <- cov_df %>%
  make_cov_table_df(offset = offset_value)#, decimals_1st_order = 1, decimals_2nd_order = 2) 
summarized <- compute_summaries(cov_df)
cov_table %>%
  display_table()
```

\begin{align*}
  c_4
    &= \frac{1}{n} \sum\limits_{t=1}^{n-1}(x_t-\bar x)(x_{t+4}-\bar x)
    = \frac{1}{`r n`} \cdot `r summarized$ss_xy`
    = `r summarized$c_k |> round(3)` \\
  r_4 
    &= \frac{c_4}{c_0} = \frac{`r summarized$c_k |> round(3)`}{`r summarized$c_0 |> round(3)`} 
    = `r summarized$r_k |> round(3)`
\end{align*}

:::

### New section 2


```{r}
#| include: false

get_data_for_cov_table <- function(offset = 1) {
  x1 <- get_toy_data()
  
  # build a data frame
  df <- data.frame(t = 1:length(x1),
                   x = x1,
                   y = lead(x1, offset)) |>
    mutate(
      xx = x - mean(x),
      xx2 = xx^2,
      yy = y - mean(x),
      # yy2 = yy^2,
      xy = xx * yy
    ) |> 
    dplyr::select(t, x, y, xx, xx2, yy, xy)
  
  return(df)
}

make_cov_table_df <- function(df, offset=1, decimals_1st_order = 5, decimals_2nd_order = 5) {
  # Color vector
  oi_colors <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#F5C710", "#CC79A7", "#999999")
  
  df_summary <- df |> 
    summarize(
      x = sum(x),
      y = sum(y, na.rm = TRUE),
      xx = sum(xx),
      yy = sum(yy, na.rm = TRUE),
      xx2 = sum(xx2),
      # yy2 = sum(yy2, na.rm = TRUE),
      xy = sum(xy, na.rm = TRUE)
    ) |> 
    # round_df(3) |> 
    mutate(t = paste0("sum")) |> 
    mutate(
      t = paste0("sum"),
      x = round_to_places(x, 1),
      y = round_to_places(y, 1),
      xx = round_to_places(xx, decimals_1st_order),
      xx2 = round_to_places(xx2, decimals_2nd_order),
      yy = round_to_places(yy, decimals_1st_order),
      # yy2 = round_to_places(yy2, decimals_2nd_order),
      xy = round_to_places(xy, decimals_2nd_order)
    ) |> 
    dplyr::select(t, x, y, xx, xx2, yy, xy)
  
  out <- df |>
    mutate(
      t = as.character(t),
      x = round_to_places(x, 1),
      y = round_to_places(y, 1),
      xx = round_to_places(xx, decimals_1st_order),
      xx2 = round_to_places(xx2, decimals_2nd_order),
      yy = round_to_places(yy, decimals_1st_order),
      # yy2 = round_to_places(yy2, decimals_2nd_order),
      xy = round_to_places(xy, decimals_2nd_order)
    ) |> 
    mutate(
      x = cell_spec(x, 
                    color = case_when(
                      is.na(x) ~ "#999999",
                      TRUE ~ oi_colors[( row_number() + 0 ) %% 9 + 1]
                    )
      ),
      y = cell_spec(y, 
                    color = case_when(
                      is.na(y) ~ "#999999",
                      TRUE ~ oi_colors[( row_number() + offset ) %% 9 + 1]
                    )
      )
    ) |> 
    mutate(
      # x = ifelse(row_number() > nrow(.) - offset, paste0("[",x,"]"), x),
      y = ifelse(row_number() > nrow(.) - offset, NA, y),
    ) |> 
    replace(., is.na(.), "—") |>
    bind_rows(df_summary) |> 
    rename(
      "x_t" = x,
      "x_{t+k}" = y,
      # paste0("x_{t+", offset, "}") = y,
      "x_t-mean(x)" = xx, 
      "(x_t-mean(x))^2" = xx2, 
      "x_{t+k}-mean(x)" = yy,
      # "(x_{t+k}-mean(x))^2" = yy2, 
      "(x-mean(x))(x_{t+k}-mean(x))" = xy
    )
  
  return(out)
}

# Compute summary values
compute_summaries <- function(df, digits = 4) {
  df |> 
    summarize(
      mean_x = mean(x),
      mean_y = mean(y, na.rm = TRUE),
      ss_x = sum(xx2),
      # ss_y = sum(yy2, na.rm = TRUE),
      ss_xy = sum(xy, na.rm = TRUE),
      c_0 = sum(xx2) / nrow(.),
      c_k = sum(xy, na.rm = TRUE) / nrow(.),
      r_k = c_k / c_0
    ) |> 
    round_df(digits)
}

```


#### Learning Outcomes

{{< include ../outcomes/_chapter_2_lesson_3_outcomes.qmd >}}





#### Preparation

-   Read Sections 2.2.5 and 2.3-2.5 (No new reading assignment)



#### Learning Journal Exchange (10 min)

-   Review another student's journal
-   What would you add to your learning journal after reading your partner's?
-   What would you recommend your partner add to their learning journal?
-   Sign the Learning Journal review sheet for your peer


#### Correlograms (10 min)

In the previous lesson, we used the following time series as an example.
Here are the values in that time series:

```{r}
#| echo: false

# simulate correlated normal random data
x1 <- get_toy_data()

cat("x <- c(",paste(x1, collapse = ", "),")")
```

-   The table below gives the sample autocorrelation function, acf, for this data set. You may recognize some of these values from the previous lesson. 

```{r}
#| echo: false

df <- data.frame(x = x1)

z <- acf(df$x, plot=FALSE, type = "correlation") 
# acf(df$x, plot=TRUE, type = "correlation") #### Solution

z$acf |> 
  data.frame() |> 
  round_df(3) |> 
  rename("acf" = "z.acf") |> 
  mutate(
    k = row_number() - 1,
    acf = as.character(acf)
  ) |> 
  pivot_wider(names_from = k, values_from = acf) |> 
  # mutate("4" = "_____") |> 
  display_table()
```

::: {.callout-tip icon=false title="Check Your Understanding"}

-   Use the acf values to sketch the correlogram for these data in your Learning Journal. The figure below can help you begin.

```{r}
#| echo: false

ggplot(data = df, aes(x = seq_along(x), y = acf(x, plot = FALSE)$acf)) +
  # geom_col() +
  ylim(-1, 1) +
  scale_x_continuous(breaks = 0:9) + 
  geom_segment(aes(x = 0, y = 0, xend = 0, yend = 1)) + 
  geom_segment(aes(x = 0, y = 0, xend = 9, yend = 0)) + #### Hack
  geom_hline(yintercept = 0, linetype = "solid", linewidth=1, color = "black") +
  geom_hline(yintercept = (2.6/4.2), linetype = "dashed", linewidth=1, color = "#0072B2") +  # Texbooks says these lines should be at (-0.1 +/- 2/sqrt(10)). Used +/-(2.6/4.2), based on measurements made visually with a ruler from the figure generated by R.
  geom_hline(yintercept = (-2.6/4.2), linetype = "dashed", linewidth=1, color = "#0072B2") +
  labs(x = "Lag", y = "ACF") +
  # theme_bw()   
  # theme(panel.grid.major.x = element_blank(), panel.grid.major.y = element_blank())
  theme_bw() +
  theme(
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank()
  )
```

<!-- -   Finish a partially-created correlogram with the r_k values computed -->

-   Are any of the autocorrelations statistically significant? If so, which one(s)?

:::

#### Application: Chocolate Search Trends (10 min)

Recall the Google Trends data for the term "chocolate" from the last lesson.
The cleaned data are available in the file <a href="data/chocolate.csv" download>chocolate.csv</a>.

##### Import the chocolate search data and convert to tsibble format

Use the code below to import the data and convert it into a time series (tsibble) object.

```{r}
#| warning: false

# load packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load("tsibble", "fable",
               "feasts", "tsibbledata",
               "fable.prophet", "tidyverse",
               "patchwork", "rio")

# read in the data from a csv and make the tsibble
# change the line below to include your file path
chocolate_month_ts <- rio::import("https://byuistats.github.io/timeseries/data/chocolate.csv") |>
  mutate(
    dates = yearmonth(ym(Month)),
    month = month(dates),
    year = year(dates),
    value = chocolate
  ) |> 
  dplyr::select(dates, month, year, value) |>
  as_tsibble(index = dates)

choc_decompose <- chocolate_month_ts |>
    model(feasts::classical_decomposition(value,
        type = "add"))  |>
    components()

autoplot(choc_decompose)
```

Here are the values of the acf for the chocolate search data:

```{r}
acf(chocolate_month_ts$value, plot=FALSE, type = "correlation", lag.max = 25)
```

Here is the associated correlogram:

```{r}
acf(chocolate_month_ts$value, plot=TRUE, type = "correlation", lag.max = 25)
```

<!-- Check Your Understanding -->

::: {.callout-tip icon=false title="Check Your Understanding"}

-   What does the information displayed in this correlogram suggest?

:::

If we consider only the random component of this time series, the correlogram is:

```{r}
acf(choc_decompose$random |> na.omit(), plot=TRUE, type = "correlation", lag.max = 25)
```

::: {.callout-tip icon=false title="Check Your Understanding"}

-   What do the spikes in the correlogram tell us about this time series?
-   Is there evidence of autocorrelation in the data after removing the trend and seasonal variation?

:::


#### Small Group Activity: BYU-Idaho On-Campus Enrollment (25 min)

The official number of on-campus BYU-Idaho students each semester is given in the file <a href="https://byuistats.github.io/timeseries/data/byui_enrollment.csv" download>byui_enrollment.csv</a>. 



::: {.callout-tip icon=false title="Check Your Understanding"}

Do the following:

-   Create a tsibble with the BYU-Idaho enrollment data. (Hint: There are three semesters in a year, so treat the enrollments as observations taken every four months in January, May, and September.)
-   Plot the decomposition of this time series.
-   Describe the trend.
-   Describe the seasonal component.
-   Is there evidence of seasonal variation? If so, propose an explanation for the seasonal variation.
-   Create the correlogram for these data. 
    -   What do you observe?
    -   Does the correlogram support the statement you made about the seasonal component?
-   Is there evidence of autocorrelation in the data after removing the trend and seasonal variation?

:::





#### Homework Preview (5 min)

-   Review upcoming homework assignment
-   Clarify questions



#### Homework

::: {.callout-note icon=false}

#### Download Homework

<a href="https://byuistats.github.io/timeseries/homework/homework_2_3.qmd" download="homework_2_3.qmd"> homework_2_3.qmd </a>

:::

<a href="javascript:showhide('Solutions')"
style="font-size:.8em;">Correlograms</a>

::: {#Solutions style="display:none;"}

Solutions to correlogram activity

```{r}
x <- c( 4.4, 4.2, 4.2, 4, 4.4, 4.7, 4.9, 5.3, 5.4, 5.5 )
acf(x, plot=FALSE, type = "correlation")
acf(x, plot=TRUE, type = "correlation")
```

:::


<a href="javascript:showhide('Solutions2')"
style="font-size:.8em;">BYU-Idaho Enrollment</a>

::: {#Solutions2 style="display:none;"}

Solutions to BYU-Idaho Enrollment Activity


```{r}
#| warning: false

# read in the data from a csv and make the tsibble

# Method 1:
enrollment_df <- rio::import("https://byuistats.github.io/timeseries/data/byui_enrollment.csv")
start_date <- lubridate::ymd("2019-05-01")
date_seq <- seq(start_date,
                start_date + months(nrow(enrollment_df)-1) * 4,
                by = "4 months")
enrollment_ts <- tibble(
    dates = tsibble::yearmonth(date_seq),
    semester = pull(enrollment_df, semester),
    enrollment = pull(enrollment_df, enrollment)
  ) |>
  dplyr::select(semester, dates, enrollment) |>
  as_tsibble(index = dates)

# Method 2:
enrollment_ts <- rio::import("https://byuistats.github.io/timeseries/data/byui_enrollment.csv") |>
  mutate(
    dates = yearmonth(ym(paste(year, term * 4 - 3)))
  ) |>
  dplyr::select(semester, dates, enrollment) |>
  as_tsibble(index = dates) 

# Compute and plot the decomposition
enrollment_decompose <- enrollment_ts |>
    model(feasts::classical_decomposition(enrollment,
        type = "add"))  |>
    components()
autoplot(enrollment_decompose)
```


```{r}
acf(enrollment_decompose$enrollment, type = "correlation")
```


```{r}
acf(enrollment_decompose$enrollment, plot=FALSE, type = "correlation")
```


```{r}
acf(enrollment_decompose$enrollment, plot=TRUE, type = "correlation")
```


```{r}
acf(enrollment_decompose$random |> na.omit(), plot=TRUE, type = "correlation")
```

:::